{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Переда запуском добавь коко2014 [датасет](https://www.kaggle.com/datasets/nadaibrahim/coco2014) в ноутбук)**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:47:45.437016Z","iopub.status.busy":"2023-12-09T21:47:45.436644Z","iopub.status.idle":"2023-12-09T21:49:50.835759Z","shell.execute_reply":"2023-12-09T21:49:50.834578Z","shell.execute_reply.started":"2023-12-09T21:47:45.436986Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.34.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","Collecting bitsandbytes\n","  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/1b/db/1a3c0d3542484806c273e8027a328b12be69c1042bb9e134efe93ddf9b50/bitsandbytes-0.41.3-py3-none-any.whl.metadata\n","  Downloading bitsandbytes-0.41.3-py3-none-any.whl.metadata (9.8 kB)\n","Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.41.3\n","Collecting ruclip==0.0.2\n","  Downloading ruclip-0.0.2-py3-none-any.whl (14 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from ruclip==0.0.2) (2.0.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from ruclip==0.0.2) (0.15.1)\n","Collecting huggingface-hub==0.2.1 (from ruclip==0.0.2)\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting youtokentome~=1.0.6 (from ruclip==0.0.2)\n","  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting more-itertools==8.12.0 (from ruclip==0.0.2)\n","  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (3.12.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (2.31.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (4.66.1)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (21.3)\n","Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.10/site-packages (from youtokentome~=1.0.6->ruclip==0.0.2) (8.1.7)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->ruclip==0.0.2) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->ruclip==0.0.2) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->ruclip==0.0.2) (3.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->ruclip==0.0.2) (1.24.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->ruclip==0.0.2) (10.1.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub==0.2.1->ruclip==0.0.2) (3.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->ruclip==0.0.2) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->ruclip==0.0.2) (1.3.0)\n","Building wheels for collected packages: youtokentome\n","  Building wheel for youtokentome (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp310-cp310-linux_x86_64.whl size=193020 sha256=977e12b65d1deb34d82a62353c90c5ea0fd94ca43b1012f02fa9ced01ceb2c08\n","  Stored in directory: /root/.cache/pip/wheels/df/85/f8/301d2ba45f43f30bed2fe413efa760bc726b8b660ed9c2900c\n","Successfully built youtokentome\n","Installing collected packages: youtokentome, more-itertools, huggingface-hub, ruclip\n","  Attempting uninstall: more-itertools\n","    Found existing installation: more-itertools 10.1.0\n","    Uninstalling more-itertools-10.1.0:\n","      Successfully uninstalled more-itertools-10.1.0\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.17.3\n","    Uninstalling huggingface-hub-0.17.3:\n","      Successfully uninstalled huggingface-hub-0.17.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.2.1 which is incompatible.\n","transformers 4.35.0 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 0.2.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.2.1 more-itertools-8.12.0 ruclip-0.0.2 youtokentome-1.0.6\n","Collecting transformers==4.27.4\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.27.4)\n","  Obtaining dependency information for huggingface-hub<1.0,>=0.11.0 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n","  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.4)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.4) (2023.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.4) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.27.4) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (2023.7.22)\n","Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.14.1\n","    Uninstalling tokenizers-0.14.1:\n","      Successfully uninstalled tokenizers-0.14.1\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.2.1\n","    Uninstalling huggingface-hub-0.2.1:\n","      Successfully uninstalled huggingface-hub-0.2.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.0\n","    Uninstalling transformers-4.35.0:\n","      Successfully uninstalled transformers-4.35.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ruclip 0.0.2 requires huggingface-hub==0.2.1, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.19.4 tokenizers-0.13.3 transformers-4.27.4\n","Collecting pycocotools\n","  Obtaining dependency information for pycocotools from https://files.pythonhosted.org/packages/ba/64/0451cf41a00fd5ac4501de4ea0e395b7d909e09d665e56890b5d3809ae26/pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n","Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.3)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.24.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n","Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pycocotools\n","Successfully installed pycocotools-2.0.7\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-yhyckpod\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-yhyckpod\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting ftfy (from clip==1.0)\n","  Obtaining dependency information for ftfy from https://files.pythonhosted.org/packages/91/f8/dfa32d06cfcbdb76bc46e0f5d69c537de33f4cedb1a15cd4746ab45a6a26/ftfy-6.1.3-py3-none-any.whl.metadata\n","  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2023.8.8)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.1)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.0.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.15.1)\n","Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->clip==1.0)\n","  Obtaining dependency information for wcwidth<0.3.0,>=0.2.12 from https://files.pythonhosted.org/packages/31/b1/a59de0ad3aabb17523a39804f4c6df3ae87ead053a4e25362ae03d73d03a/wcwidth-0.2.12-py2.py3-none-any.whl.metadata\n","  Downloading wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.24.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m759.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n","\u001b[?25hDownloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=e026dc56d9c4d2041fd062cf94b0915d563bcb7a3fdf0b24e24581d3a2e1eba6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fr65bdnh/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n","Successfully built clip\n","Installing collected packages: wcwidth, ftfy, clip\n","  Attempting uninstall: wcwidth\n","    Found existing installation: wcwidth 0.2.6\n","    Uninstalling wcwidth-0.2.6:\n","      Successfully uninstalled wcwidth-0.2.6\n","Successfully installed clip-1.0 ftfy-6.1.3 wcwidth-0.2.12\n","Collecting open_clip_torch\n","  Obtaining dependency information for open_clip_torch from https://files.pythonhosted.org/packages/7c/7f/952fdffa17b15d0c7c51a730860fcf4f4982528ecc753b190dcd46cc944b/open_clip_torch-2.23.0-py3-none-any.whl.metadata\n","  Downloading open_clip_torch-2.23.0-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2.0.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.15.1)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2023.8.8)\n","Requirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (6.1.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (4.66.1)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.19.4)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.1.99)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (3.20.3)\n","Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.9.10)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch) (0.2.12)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2023.10.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (6.0.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (21.3)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open_clip_torch) (0.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (1.24.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (10.1.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n","Downloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: open_clip_torch\n","Successfully installed open_clip_torch-2.23.0\n"]}],"source":["!pip install wandb\n","!pip install bitsandbytes\n","!pip install ruclip==0.0.2\n","!pip install transformers==4.27.4\n","!pip install pycocotools\n","!pip install git+https://github.com/openai/CLIP.git\n","!pip install open_clip_torch"]},{"cell_type":"markdown","metadata":{},"source":["#### Качаем РУССКИЙ капчеринг"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:49:50.838077Z","iopub.status.busy":"2023-12-09T21:49:50.837728Z","iopub.status.idle":"2023-12-09T21:49:50.842427Z","shell.execute_reply":"2023-12-09T21:49:50.841607Z","shell.execute_reply.started":"2023-12-09T21:49:50.838044Z"},"trusted":true},"outputs":[],"source":["#!rm -rf ru_capt.json\n","##!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1uIO34T8d0ML23I30mcRFAD7niggm1kIt' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1uIO34T8d0ML23I30mcRFAD7niggm1kIt\" -O ru_capt.json && rm -rf /tmp/cookies.txt"]},{"cell_type":"markdown","metadata":{},"source":["#### Качаем ембединги датасета"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:49:50.843746Z","iopub.status.busy":"2023-12-09T21:49:50.843468Z","iopub.status.idle":"2023-12-09T21:49:59.829821Z","shell.execute_reply":"2023-12-09T21:49:59.828728Z","shell.execute_reply.started":"2023-12-09T21:49:50.843700Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-12-09 21:49:51--  https://docs.google.com/uc?export=download&confirm=t&id=11OpNsXhmtafzItkGxaTqMXqgL2dQycl6\n","Resolving docs.google.com (docs.google.com)... 172.217.204.113, 172.217.204.138, 172.217.204.101, ...\n","Connecting to docs.google.com (docs.google.com)|172.217.204.113|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-00-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/s86sfgik1noejs9qalbnnap6td0354cb/1702158525000/09074642392443333439/*/11OpNsXhmtafzItkGxaTqMXqgL2dQycl6?e=download&uuid=b496b4b1-9aa3-4b28-8af8-0d5cabb9a069 [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-12-09 21:49:52--  https://doc-00-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/s86sfgik1noejs9qalbnnap6td0354cb/1702158525000/09074642392443333439/*/11OpNsXhmtafzItkGxaTqMXqgL2dQycl6?e=download&uuid=b496b4b1-9aa3-4b28-8af8-0d5cabb9a069\n","Resolving doc-00-38-docs.googleusercontent.com (doc-00-38-docs.googleusercontent.com)... 142.251.107.132, 2607:f8b0:400c:c32::84\n","Connecting to doc-00-38-docs.googleusercontent.com (doc-00-38-docs.googleusercontent.com)|142.251.107.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 215682436 (206M) [application/zip]\n","Saving to: ‘train2014_emb.zip’\n","\n","train2014_emb.zip   100%[===================>] 205.69M   244MB/s    in 0.8s    \n","\n","2023-12-09 21:49:53 (244 MB/s) - ‘train2014_emb.zip’ saved [215682436/215682436]\n","\n","Archive:  train2014_emb.zip\n","  inflating: Features_train_coco_ru_vitb16_82783.pkl  \n","  inflating: __MACOSX/._Features_train_coco_ru_vitb16_82783.pkl  \n"]}],"source":["#!rm -rf train2014_emb.zip\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11OpNsXhmtafzItkGxaTqMXqgL2dQycl6' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11OpNsXhmtafzItkGxaTqMXqgL2dQycl6\" -O train2014_emb.zip && rm -rf /tmp/cookies.txt\n","!unzip train2014_emb.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:49:59.832427Z","iopub.status.busy":"2023-12-09T21:49:59.832117Z","iopub.status.idle":"2023-12-09T21:50:05.315005Z","shell.execute_reply":"2023-12-09T21:50:05.313891Z","shell.execute_reply.started":"2023-12-09T21:49:59.832397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-12-09 21:50:00--  https://docs.google.com/uc?export=download&confirm=t&id=1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0\n","Resolving docs.google.com (docs.google.com)... 172.217.204.102, 172.217.204.101, 172.217.204.100, ...\n","Connecting to docs.google.com (docs.google.com)|172.217.204.102|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-0s-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c4iupmnhg0alg6ov9c35qvbbpqr48a4k/1702158600000/09074642392443333439/*/1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0?e=download&uuid=5ace0edc-505a-43ee-a8cc-f9b3f7fff24e [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-12-09 21:50:00--  https://doc-0s-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c4iupmnhg0alg6ov9c35qvbbpqr48a4k/1702158600000/09074642392443333439/*/1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0?e=download&uuid=5ace0edc-505a-43ee-a8cc-f9b3f7fff24e\n","Resolving doc-0s-38-docs.googleusercontent.com (doc-0s-38-docs.googleusercontent.com)... 142.251.107.132, 2607:f8b0:400c:c32::84\n","Connecting to doc-0s-38-docs.googleusercontent.com (doc-0s-38-docs.googleusercontent.com)|142.251.107.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 105531134 (101M) [application/zip]\n","Saving to: ‘val2014_emb.zip’\n","\n","val2014_emb.zip     100%[===================>] 100.64M   245MB/s    in 0.4s    \n","\n","2023-12-09 21:50:01 (245 MB/s) - ‘val2014_emb.zip’ saved [105531134/105531134]\n","\n","Archive:  val2014_emb.zip\n","  inflating: Features_val_coco_ru_vitb16.pkl  \n","  inflating: __MACOSX/._Features_val_coco_ru_vitb16.pkl  \n"]}],"source":["#!rm -rf val2014_emb.zip\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0\" -O val2014_emb.zip && rm -rf /tmp/cookies.txt\n","!unzip val2014_emb.zip\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:05.317263Z","iopub.status.busy":"2023-12-09T21:50:05.316565Z","iopub.status.idle":"2023-12-09T21:50:05.321602Z","shell.execute_reply":"2023-12-09T21:50:05.320649Z","shell.execute_reply.started":"2023-12-09T21:50:05.317231Z"},"trusted":true},"outputs":[],"source":["#import torchvision.datasets as dset\n","#coco_train = dset.CocoDetection(\n","#    root = \"/kaggle/input/coco2014/train2014/train2014\",\n","#    annFile = \"/kaggle/input/coco2014/captions/annotations/captions_train2014.json\"\n","#)\n","#coco_val = dset.CocoDetection(\n","#    root = \"/kaggle/input/coco2014/val2014/val2014\",\n","#    annFile = \"/kaggle/input/coco2014/captions/annotations/captions_val2014.json\"\n","#)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:05.322996Z","iopub.status.busy":"2023-12-09T21:50:05.322701Z","iopub.status.idle":"2023-12-09T21:50:08.438475Z","shell.execute_reply":"2023-12-09T21:50:08.437626Z","shell.execute_reply.started":"2023-12-09T21:50:05.322971Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as nnf\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:08.440611Z","iopub.status.busy":"2023-12-09T21:50:08.439870Z","iopub.status.idle":"2023-12-09T21:50:13.151803Z","shell.execute_reply":"2023-12-09T21:50:13.151005Z","shell.execute_reply.started":"2023-12-09T21:50:08.440571Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm, trange\n","import os\n","import pickle\n","import sys\n","import argparse\n","import json\n","from typing import Tuple, Optional, Union\n","from torch.cuda.amp import autocast\n","\n","import ruclip\n","import clip, open_clip\n","import random"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:13.153277Z","iopub.status.busy":"2023-12-09T21:50:13.152981Z","iopub.status.idle":"2023-12-09T21:50:13.377610Z","shell.execute_reply":"2023-12-09T21:50:13.376749Z","shell.execute_reply.started":"2023-12-09T21:50:13.153250Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Config, GPT2Model\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:13.379581Z","iopub.status.busy":"2023-12-09T21:50:13.378985Z","iopub.status.idle":"2023-12-09T21:50:24.192332Z","shell.execute_reply":"2023-12-09T21:50:24.191341Z","shell.execute_reply.started":"2023-12-09T21:50:13.379542Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from transformers import AdamW, get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.197439Z","iopub.status.busy":"2023-12-09T21:50:24.196877Z","iopub.status.idle":"2023-12-09T21:50:24.202686Z","shell.execute_reply":"2023-12-09T21:50:24.201589Z","shell.execute_reply.started":"2023-12-09T21:50:24.197403Z"},"trusted":true},"outputs":[],"source":["#from multilingual_clip import pt_multilingual_clip"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.204784Z","iopub.status.busy":"2023-12-09T21:50:24.204072Z","iopub.status.idle":"2023-12-09T21:50:24.222261Z","shell.execute_reply":"2023-12-09T21:50:24.221283Z","shell.execute_reply.started":"2023-12-09T21:50:24.204749Z"},"trusted":true},"outputs":[],"source":["manualSeed = 1337\n","#manualSeed = random.randint(1, 10000) # use if you want new results\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.223775Z","iopub.status.busy":"2023-12-09T21:50:24.223434Z","iopub.status.idle":"2023-12-09T21:50:24.231549Z","shell.execute_reply":"2023-12-09T21:50:24.230754Z","shell.execute_reply.started":"2023-12-09T21:50:24.223735Z"},"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, sizes: Tuple[int, ...], bias=True, act=nn.Tanh):\n","        super(MLP, self).__init__()\n","        layers = []\n","        for i in range(len(sizes) - 1):\n","            layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=bias))\n","            if i < len(sizes) - 2:\n","                layers.append(act())\n","        self.model = nn.Sequential(*layers)\n","    \n","    @autocast()  \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.model(x)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.233132Z","iopub.status.busy":"2023-12-09T21:50:24.232796Z","iopub.status.idle":"2023-12-09T21:50:24.241609Z","shell.execute_reply":"2023-12-09T21:50:24.240866Z","shell.execute_reply.started":"2023-12-09T21:50:24.233107Z"},"trusted":true},"outputs":[],"source":["class MlpTransformer(nn.Module):\n","    def __init__(self, in_dim, h_dim, out_d: Optional[int] = None, act=nnf.relu, dropout=0.):\n","        super().__init__()\n","        out_d = out_d if out_d is not None else in_dim\n","        self.fc1 = nn.Linear(in_dim, h_dim)\n","        self.act = act\n","        self.fc2 = nn.Linear(h_dim, out_d)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.dropout(x)\n","        return x"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.243034Z","iopub.status.busy":"2023-12-09T21:50:24.242610Z","iopub.status.idle":"2023-12-09T21:50:24.257637Z","shell.execute_reply":"2023-12-09T21:50:24.256843Z","shell.execute_reply.started":"2023-12-09T21:50:24.242972Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","\n","    def __init__(self, dim_self, dim_ref, num_heads, bias=True, dropout=0.):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        head_dim = dim_self // num_heads\n","        self.scale = head_dim ** -0.5\n","        self.to_queries = nn.Linear(dim_self, dim_self, bias=bias)\n","        self.to_keys_values = nn.Linear(dim_ref, dim_self * 2, bias=bias)\n","        self.project = nn.Linear(dim_self, dim_self)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, y=None, mask=None):\n","        y = y if y is not None else x\n","        b, n, c = x.shape\n","        _, m, d = y.shape\n","        # b n h dh\n","        queries = self.to_queries(x).reshape(b, n, self.num_heads, c // self.num_heads)\n","        # b m 2 h dh\n","        keys_values = self.to_keys_values(y).reshape(b, m, 2, self.num_heads, c // self.num_heads)\n","        keys, values = keys_values[:, :, 0], keys_values[:, :, 1]\n","        attention = torch.einsum('bnhd,bmhd->bnmh', queries, keys) * self.scale\n","        if mask is not None:\n","            if mask.dim() == 2:\n","                mask = mask.unsqueeze(1)\n","            attention = attention.masked_fill(mask.unsqueeze(3), float(\"-inf\"))\n","        attention = attention.softmax(dim=2)\n","        out = torch.einsum('bnmh,bmhd->bnhd', attention, values).reshape(b, n, c)\n","        out = self.project(out)\n","        return out, attention"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.260568Z","iopub.status.busy":"2023-12-09T21:50:24.260280Z","iopub.status.idle":"2023-12-09T21:50:24.277853Z","shell.execute_reply":"2023-12-09T21:50:24.276938Z","shell.execute_reply.started":"2023-12-09T21:50:24.260542Z"},"trusted":true},"outputs":[],"source":["class TransformerLayer(nn.Module):\n","\n","    def forward_with_attention(self, x, y=None, mask=None):\n","        x_, attention = self.attn(self.norm1(x), y, mask)\n","        x = x + x_\n","        x = x + self.mlp(self.norm2(x))\n","        return x, attention\n","\n","    def forward(self, x, y=None, mask=None):\n","        x = x + self.attn(self.norm1(x), y, mask)[0]\n","        x = x + self.mlp(self.norm2(x))\n","        return x\n","\n","    def __init__(self, dim_self, dim_ref, num_heads, mlp_ratio=4., bias=False, dropout=0., act=nnf.relu,\n","                 norm_layer: nn.Module = nn.LayerNorm):\n","        super().__init__()\n","        self.norm1 = norm_layer(dim_self)\n","        self.attn = MultiHeadAttention(dim_self, dim_ref, num_heads, bias=bias, dropout=dropout)\n","        self.norm2 = norm_layer(dim_self)\n","        self.mlp = MlpTransformer(dim_self, int(dim_self * mlp_ratio), act=act, dropout=dropout)\n","\n","\n","class Transformer(nn.Module):\n","\n","    def forward_with_attention(self, x, y=None, mask=None):\n","        attentions = []\n","        for layer in self.layers:\n","            x, att = layer.forward_with_attention(x, y, mask)\n","            attentions.append(att)\n","        return x, attentions\n","\n","    def forward(self, x, y=None, mask=None):\n","        for i, layer in enumerate(self.layers):\n","            if i % 2 == 0 and self.enc_dec: # cross\n","                x = layer(x, y)\n","            elif self.enc_dec:  # self\n","                x = layer(x, x, mask)\n","            else:  # self or cross\n","                x = layer(x, y, mask)\n","        return x\n","\n","    def __init__(self, dim_self: int, num_heads: int, num_layers: int, dim_ref: Optional[int] = None,\n","                 mlp_ratio: float = 2., act=nnf.relu, norm_layer: nn.Module = nn.LayerNorm, enc_dec: bool = False):\n","        super(Transformer, self).__init__()\n","        dim_ref = dim_ref if dim_ref is not None else dim_self\n","        self.enc_dec = enc_dec\n","        if enc_dec:\n","            num_layers = num_layers * 2\n","        layers = []\n","        for i in range(num_layers):\n","            if i % 2 == 0 and enc_dec:  # cross\n","                layers.append(TransformerLayer(dim_self, dim_ref, num_heads, mlp_ratio, act=act, norm_layer=norm_layer))\n","            elif enc_dec:  # self\n","                layers.append(TransformerLayer(dim_self, dim_self, num_heads, mlp_ratio, act=act, norm_layer=norm_layer))\n","            else:  # self or cross\n","                layers.append(TransformerLayer(dim_self, dim_ref, num_heads, mlp_ratio, act=act, norm_layer=norm_layer))\n","        self.layers = nn.ModuleList(layers)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.279174Z","iopub.status.busy":"2023-12-09T21:50:24.278891Z","iopub.status.idle":"2023-12-09T21:50:24.292191Z","shell.execute_reply":"2023-12-09T21:50:24.291331Z","shell.execute_reply.started":"2023-12-09T21:50:24.279150Z"},"trusted":true},"outputs":[],"source":["class TransformerMapper(nn.Module):\n","\n","    def forward(self, x):\n","        x = self.linear(x).view(x.shape[0], self.clip_length, -1)\n","        prefix = self.prefix_const.unsqueeze(0).expand(x.shape[0], *self.prefix_const.shape)\n","        prefix = torch.cat((x, prefix), dim=1)\n","        out = self.transformer(prefix)[:, self.clip_length:]\n","        return out\n","\n","    def __init__(self, dim_clip: int, dim_embedding: int, prefix_length: int, clip_length: int, num_layers: int = 8):\n","        super(TransformerMapper, self).__init__()\n","        self.clip_length = clip_length\n","        self.transformer = Transformer(dim_embedding, 8, num_layers)\n","        self.linear = nn.Linear(dim_clip, clip_length * dim_embedding)\n","        self.prefix_const = nn.Parameter(torch.randn(prefix_length, dim_embedding), requires_grad=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.293863Z","iopub.status.busy":"2023-12-09T21:50:24.293477Z","iopub.status.idle":"2023-12-09T21:50:24.302656Z","shell.execute_reply":"2023-12-09T21:50:24.301769Z","shell.execute_reply.started":"2023-12-09T21:50:24.293829Z"},"trusted":true},"outputs":[],"source":["def freeze(\n","    model,\n","    freeze_emb=False,\n","    freeze_ln=False,\n","    freeze_attn=True,\n","    freeze_ff=True,\n","    freeze_other=False,\n","):\n","    \n","    for name, p in model.named_parameters():\n","    # freeze all parameters except the layernorm and positional embeddings\n","        name = name.lower()\n","        if 'ln' in name or 'norm' in name:\n","            p.requires_grad = not freeze_ln\n","        elif 'embeddings' in name:\n","            p.requires_grad = not freeze_emb\n","        elif 'mlp' in name:\n","            p.requires_grad = not freeze_ff\n","        elif 'attn' in name:\n","            p.requires_grad = not freeze_attn\n","        else:\n","            p.requires_grad = not freeze_other\n","           \n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.304372Z","iopub.status.busy":"2023-12-09T21:50:24.303932Z","iopub.status.idle":"2023-12-09T21:50:24.312996Z","shell.execute_reply":"2023-12-09T21:50:24.312218Z","shell.execute_reply.started":"2023-12-09T21:50:24.304318Z"},"trusted":true},"outputs":[],"source":["from enum import Enum\n","class MappingType(Enum):\n","    MLP = 'mlp'\n","    Transformer = 'transformer'"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.314336Z","iopub.status.busy":"2023-12-09T21:50:24.314071Z","iopub.status.idle":"2023-12-09T21:50:24.328302Z","shell.execute_reply":"2023-12-09T21:50:24.327462Z","shell.execute_reply.started":"2023-12-09T21:50:24.314312Z"},"trusted":true},"outputs":[],"source":["gpt_model_name = 'sberbank-ai/rugpt3medium_based_on_gpt2'\n","class ClipCaptionModel(nn.Module):\n","    def __init__(\n","        self,\n","        prefix_length: int,\n","        clip_length: Optional[int] = None,\n","        prefix_size: int = 640,\n","        num_layers: int = 8,\n","        mapping_type: MappingType = MappingType.MLP\n","    ):\n","        super(ClipCaptionModel, self).__init__()\n","        self.prefix_length = prefix_length\n","\n","        self.gpt = GPT2LMHeadModel.from_pretrained(gpt_model_name)\n","        self.gpt_embedding_size = self.gpt.transformer.wte.weight.shape[1]\n","\n","        if mapping_type == MappingType.MLP:\n","            self.clip_project = MLP((\n","                prefix_size,\n","                self.gpt_embedding_size * prefix_length // 2,\n","                self.gpt_embedding_size * prefix_length\n","            ))\n","        else:\n","            self.clip_project = TransformerMapper(\n","                prefix_size,\n","                self.gpt_embedding_size,\n","                prefix_length,\n","                clip_length, \n","                num_layers\n","            )\n","\n","        \n","    def get_dummy_token(self, batch_size: int, device: torch.device) -> torch.Tensor:\n","        return torch.zeros(batch_size, self.prefix_length, dtype=torch.int64, device=device)\n","    \n","    @autocast() \n","    def forward(\n","        self,        \n","        tokens: torch.Tensor,\n","        prefix: torch.Tensor,\n","        mask: Optional[torch.Tensor] = None,\n","        labels: Optional[torch.Tensor] = None\n","    ):\n","        embedding_text = self.gpt.transformer.wte(tokens)\n","        prefix_projections = self.clip_project(\n","            prefix.float()\n","        ).view(-1, self.prefix_length, self.gpt_embedding_size)\n","\n","        embedding_cat = torch.cat((prefix_projections, embedding_text), dim=1)\n","\n","        if labels is not None:\n","            dummy_token = self.get_dummy_token(tokens.shape[0], tokens.device)\n","            labels = torch.cat((dummy_token, tokens), dim=1)\n","        out = self.gpt(inputs_embeds=embedding_cat, labels=labels, attention_mask=mask)\n","        \n","        return out"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.329751Z","iopub.status.busy":"2023-12-09T21:50:24.329376Z","iopub.status.idle":"2023-12-09T21:50:24.342497Z","shell.execute_reply":"2023-12-09T21:50:24.341495Z","shell.execute_reply.started":"2023-12-09T21:50:24.329697Z"},"trusted":true},"outputs":[],"source":["class ClipCaptionPrefix(ClipCaptionModel):\n","    def parameters(self, recurse: bool = True):\n","        return self.clip_project.parameters()\n","\n","    def train(self, mode: bool = True):\n","        super(ClipCaptionPrefix, self).train(mode)\n","        self.gpt.eval()\n","        return self"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.344132Z","iopub.status.busy":"2023-12-09T21:50:24.343796Z","iopub.status.idle":"2023-12-09T21:50:24.356764Z","shell.execute_reply":"2023-12-09T21:50:24.355921Z","shell.execute_reply.started":"2023-12-09T21:50:24.344102Z"},"trusted":true},"outputs":[],"source":["path_emb_train_coco = f\"Features_train_coco_ru_vitb16_82783.pkl\"\n","path_emb_val_coco = f\"Features_val_coco_ru_vitb16.pkl\""]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.358155Z","iopub.status.busy":"2023-12-09T21:50:24.357870Z","iopub.status.idle":"2023-12-09T21:50:24.373688Z","shell.execute_reply":"2023-12-09T21:50:24.372794Z","shell.execute_reply.started":"2023-12-09T21:50:24.358129Z"},"trusted":true},"outputs":[],"source":["class ClipCocoDataset(Dataset):\n","    def __init__(\n","        self,\n","        data_path: str,\n","        prefix_length=30,\n","        model_type = gpt_model_name,\n","        normalize_prefix=False,\n","        train=True,\n","    ):\n","\n","        self.tokenizer = GPT2Tokenizer.from_pretrained(model_type)\n","        self.prefix_length = prefix_length\n","        self.normalize_prefix = normalize_prefix\n","        if train:\n","            with open(data_path, 'rb') as f:\n","                all_data = pickle.load(f)\n","            print(\"Data size is %0d\" % len(all_data[\"clip_embedding\"]))\n","        else:\n","            with open(data_path, 'rb') as f:\n","                all_data = pickle.load(f)\n","            print(\"Data size is %0d\" % len(all_data[\"clip_embedding\"]))\n","\n","        sys.stdout.flush()\n","        self.prefixes = all_data[\"clip_embedding\"]\n","        captions_raw = all_data[\"captions\"]\n","        \n","        self.captions = captions_raw\n","\n","        self.captions_tokens = []\n","        self.caption2embedding = []\n","        max_seq_len = 0\n","        i = 0\n","        for caption in tqdm(captions_raw):\n","            self.captions_tokens.append(\n","                torch.tensor(self.tokenizer.encode(caption), dtype=torch.int64)\n","            )\n","            self.caption2embedding.append(self.prefixes[i])\n","            i += 1\n","            max_seq_len = max(max_seq_len, self.captions_tokens[-1].shape[0])\n","\n","        all_len = torch.tensor([len(self.captions_tokens[i]) for i in range(len(self))]).float()\n","        self.max_seq_len = min(int(all_len.mean() + all_len.std() * 10), int(all_len.max()))\n","\n","    def pad_tokens(self, item: int):\n","        tokens = self.captions_tokens[item]\n","        padding = self.max_seq_len - tokens.shape[0]\n","        if padding > 0:\n","            tokens = torch.cat((tokens, torch.zeros(padding, dtype=torch.int64) - 1))\n","            #self.captions_tokens[item] = tokens\n","        elif padding < 0:\n","            tokens = tokens[:self.max_seq_len]\n","            #self.captions_tokens[item] = tokens\n","        mask = tokens.ge(0)  # mask is zero where we out of sequence\n","        tokens[~mask] = 0\n","        mask = mask.float()\n","        mask = torch.cat((torch.ones(self.prefix_length), mask), dim=0)  # adding prefix mask\n","        return tokens, mask\n","    \n","    def __len__(self) -> int:\n","        return len(self.captions_tokens)\n","\n","    def __getitem__(self, item):\n","        tokens, mask = self.pad_tokens(item)\n","        prefix = self.prefixes[item]\n","        if self.normalize_prefix:\n","            prefix = prefix.float()\n","            prefix = prefix / prefix.norm(2, -1)\n","        return tokens, mask, prefix"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.375898Z","iopub.status.busy":"2023-12-09T21:50:24.375033Z","iopub.status.idle":"2023-12-09T21:50:24.388337Z","shell.execute_reply":"2023-12-09T21:50:24.387485Z","shell.execute_reply.started":"2023-12-09T21:50:24.375862Z"},"trusted":true},"outputs":[],"source":["def save_config(args: argparse.Namespace):\n","    config = {}\n","    for key, item in args._get_kwargs():\n","        config[key] = item\n","    out_path = os.path.join(args.out_dir, f\"{args.prefix}.json\")\n","    with open(out_path, 'w') as outfile:\n","        json.dump(config, outfile)\n","\n","\n","def load_model(config_path: str, epoch_or_latest: Union[str, int] = '_latest'):\n","    with open(config_path) as f:\n","        config = json.load(f)\n","    parser = argparse.ArgumentParser()\n","    parser.set_defaults(**config)\n","    args = parser.parse_args()\n","    if type(epoch_or_latest) is int:\n","        epoch_or_latest = f\"-{epoch_or_latest:03d}\"\n","    model_path = os.path.join(args.out_dir, f\"{args.prefix}{epoch_or_latest}.pt\")\n","    if args.only_prefix:\n","        model = ClipCaptionPrefix(args.prefix_length)\n","    else:\n","        model = ClipCaptionModel(args.prefix_length)\n","    if os.path.isfile(model_path):\n","        print(f\"loading model from {model_path}\")\n","        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","    else:\n","        print(f\"{model_path} is not exist\")\n","    return model, parser\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.389829Z","iopub.status.busy":"2023-12-09T21:50:24.389393Z","iopub.status.idle":"2023-12-09T21:50:24.402909Z","shell.execute_reply":"2023-12-09T21:50:24.401920Z","shell.execute_reply.started":"2023-12-09T21:50:24.389802Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Tesla P100-PCIE-16GB'"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.get_device_name(0)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:24.404547Z","iopub.status.busy":"2023-12-09T21:50:24.404164Z","iopub.status.idle":"2023-12-09T21:50:29.773326Z","shell.execute_reply":"2023-12-09T21:50:29.772195Z","shell.execute_reply.started":"2023-12-09T21:50:24.404509Z"},"trusted":true},"outputs":[{"data":{"text/plain":["15.8992919921875"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.mem_get_info()[1] / 1024**3"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:29.775189Z","iopub.status.busy":"2023-12-09T21:50:29.774817Z","iopub.status.idle":"2023-12-09T21:50:30.062428Z","shell.execute_reply":"2023-12-09T21:50:30.061347Z","shell.execute_reply.started":"2023-12-09T21:50:29.775156Z"},"trusted":true},"outputs":[],"source":["import bitsandbytes as bnb"]},{"cell_type":"markdown","metadata":{},"source":["## **TRAIN**"]},{"cell_type":"markdown","metadata":{},"source":["**Запусти ячейку и появится окошко для ввода токена)**"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:50:30.064844Z","iopub.status.busy":"2023-12-09T21:50:30.064085Z","iopub.status.idle":"2023-12-09T21:51:54.326808Z","shell.execute_reply":"2023-12-09T21:51:54.325830Z","shell.execute_reply.started":"2023-12-09T21:50:30.064799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:51:56.990015Z","iopub.status.busy":"2023-12-09T21:51:56.989260Z","iopub.status.idle":"2023-12-09T21:52:27.809442Z","shell.execute_reply":"2023-12-09T21:52:27.808514Z","shell.execute_reply.started":"2023-12-09T21:51:56.989978Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrbeketov\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231209_215157-6ufurfrs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rbeketov/ClipCap_NAS/runs/6ufurfrs' target=\"_blank\">MLP&GPT-2-BLEU</a></strong> to <a href='https://wandb.ai/rbeketov/ClipCap_NAS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rbeketov/ClipCap_NAS' target=\"_blank\">https://wandb.ai/rbeketov/ClipCap_NAS</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rbeketov/ClipCap_NAS/runs/6ufurfrs' target=\"_blank\">https://wandb.ai/rbeketov/ClipCap_NAS/runs/6ufurfrs</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rbeketov/ClipCap_NAS/runs/6ufurfrs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f762d52aa70>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","\n","wandb.init(project=\"ClipCap_NAS\", name=\"MLP&GPT-2-BLEU\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:52:27.811300Z","iopub.status.busy":"2023-12-09T21:52:27.811013Z","iopub.status.idle":"2023-12-09T21:52:27.817380Z","shell.execute_reply":"2023-12-09T21:52:27.816357Z","shell.execute_reply.started":"2023-12-09T21:52:27.811274Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","import os\n","import pickle\n","import sys\n","import argparse\n","\n","from typing import Tuple, Optional, Union\n","from torch.cuda.amp import autocast\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:52:27.818798Z","iopub.status.busy":"2023-12-09T21:52:27.818423Z","iopub.status.idle":"2023-12-09T21:52:28.754238Z","shell.execute_reply":"2023-12-09T21:52:28.753288Z","shell.execute_reply.started":"2023-12-09T21:52:27.818764Z"},"trusted":true},"outputs":[],"source":["import nltk"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:52:28.757475Z","iopub.status.busy":"2023-12-09T21:52:28.756870Z","iopub.status.idle":"2023-12-09T21:52:29.137129Z","shell.execute_reply":"2023-12-09T21:52:29.136176Z","shell.execute_reply.started":"2023-12-09T21:52:28.757424Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, load_metric"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:52:29.138905Z","iopub.status.busy":"2023-12-09T21:52:29.138258Z","iopub.status.idle":"2023-12-09T21:52:29.145457Z","shell.execute_reply":"2023-12-09T21:52:29.144522Z","shell.execute_reply.started":"2023-12-09T21:52:29.138877Z"},"trusted":true},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","\n","def calc_bleu(y_pred, y_true):\n","    references = [[reference.split()] for reference in y_true]\n","    hypotheses = [hypothesis.split() for hypothesis in y_pred]\n","    # Рассчитываем BLEU-4\n","    bleu_score = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n","    return bleu_score*100"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T00:51:52.821305Z","iopub.status.busy":"2023-12-10T00:51:52.820933Z","iopub.status.idle":"2023-12-10T00:51:52.847842Z","shell.execute_reply":"2023-12-10T00:51:52.846656Z","shell.execute_reply.started":"2023-12-10T00:51:52.821274Z"},"trusted":true},"outputs":[],"source":["def train(\n","    train_dataset: ClipCocoDataset,\n","    train_dataloader,\n","    #valid_dataset: ClipCocoDataset,\n","    model: ClipCaptionModel,\n","    optimizer,\n","    scheduler,\n","    args,\n","    warmup_steps: int = 5000,\n","    output_dir: str = \".\",\n","    output_prefix: str = \"\"\n","):\n","    #\n","    batch_size = args.bs\n","    epochs = args.epochs\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    model = freeze(model)\n","\n","\n","    model.train()\n","\n","    #optimizer = Adafactor(\n","    #    model.parameters(),\n","    #    lr=args.lr,\n","    #    relative_step=False, # for adafactor\n","    #)\n","    \n","\n","    \n","    #valid_dataloader = DataLoader(\n","    #    valid_dataset,\n","    #    batch_size=batch_size,\n","    #    shuffle=False,\n","    #    drop_last=False,\n","    #)\n","    \n","    \n","    #scheduler = AdafactorSchedule(optimizer) работает не оч\n","\n","    mean_epoch_train_loss = []\n","    mean_bleu_train_epoch = []\n","    \n","    \n","    for epoch in range(epochs):\n","        loss_train_epoch = []\n","        bleu_train_epoch = []\n","        print(f\">>> Training epoch {epoch+1}\")\n","        sys.stdout.flush()\n","        progress = tqdm(total=len(train_dataloader), desc=output_prefix)\n","        step=0\n","        for idx, (tokens, mask, prefix) in enumerate(train_dataloader):\n","            model.zero_grad()\n","            step += 1\n","            tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.bfloat16)\n","            \n","            outputs = model(tokens, prefix, mask)\n","            logits = outputs.logits[:, train_dataset.prefix_length - 1: -1]\n","\n","            loss = nnf.cross_entropy(\n","                logits.reshape(-1, logits.shape[-1]),\n","                tokens.flatten().to(torch.int64),\n","                ignore_index=0\n","            )\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            optimizer.zero_grad()\n","            progress.set_postfix({\"loss_train\": loss.item()})\n","            \n","\n","            loss_train_epoch.append(loss.item())\n","\n","            if step % 500 == 0:\n","                wandb.log({\"loss_train\":  loss.item()})\n","            \n","            if step % 1000 == 0:\n","                with torch.no_grad():\n","                    # BLEU-4\n","                    logits_cpu = logits.cpu()\n","                    tokens_cpu = tokens.cpu()\n","                    generated_texts = []\n","                    real_text = []\n","                    for b in range(batch_size):\n","                        generated_text_batch = train_dataset.tokenizer.decode(logits_cpu[b].argmax(dim=-1).tolist())\n","                        first_dot_index = generated_text_batch.find('.')\n","                        if first_dot_index != -1:\n","                            generated_texts.append(generated_text_batch[35:first_dot_index + 1])\n","                        else:\n","                            generated_texts.append(generated_text_batch[35:])\n","                        \n","                        real_text_batch = train_dataset.tokenizer.decode(tokens_cpu[b].tolist())\n","                        first_pad_index = real_text_batch.find('<pad>')\n","                        if first_pad_index != -1:\n","                            real_text.append(real_text_batch[35:first_pad_index])\n","                        else:\n","                            real_text.append(real_text_batch[35:])\n","                    \n","                    bleu = calc_bleu(generated_texts, real_text)\n","                    wandb.log({\"bleu-4 train\":  bleu})\n","                    bleu_train_epoch.append(bleu)\n","                    \n","\n","            progress.update()\n","            if (idx + 1) % 7000 == 0:\n","                torch.save(\n","                    model.state_dict(),\n","                    os.path.join(output_dir, f\"{output_prefix}_latest_gpt2_medium.pt\"),\n","                )\n","        progress.close()\n","        if epoch % args.save_every == 0:\n","            torch.save(\n","                model.state_dict(),\n","                os.path.join(output_dir, f\"{output_prefix}-{(epoch+1):03d}_gpt2_medium.pt\"),\n","            )\n","        mean_epoch_train_loss.append(np.mean(loss_train_epoch))\n","        mean_bleu_train_epoch.append(np.mean(bleu_train_epoch))\n","        \n","        wandb.log({\"mean_epoch_train_loss\": mean_epoch_train_loss[-1]})\n","        wandb.log({\"mean_bleu_train_epoch\": mean_bleu_train_epoch[-1]})\n","        \n","        \n","        '''\n","        print(f\">>> Validation epoch {epoch+1}\")\n","\n","        progress = tqdm(total=len(valid_dataloader), desc=output_prefix)\n","        step_validation=0\n","        for idx, (tokens, mask, prefix) in enumerate(valid_dataloader):\n","            step_validation+=1\n","            with torch.no_grad():\n","\n","                tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.bfloat16)\n","            \n","                outputs = model(tokens, prefix, mask)\n","                logits = outputs.logits[:, valid_dataset.prefix_length - 1: -1]\n","\n","                loss = nnf.cross_entropy(\n","                    logits.reshape(-1, logits.shape[-1]),\n","                    tokens.flatten().to(torch.int64),\n","                    ignore_index=0\n","                )\n","\n","\n","\n","            progress.set_postfix({\"loss_val\": loss.item()})\n","\n","            loss_valid_epoch.append(loss.item())\n","            if step % 500:\n","                wandb.log({\"loss_val\":  loss.item()})\n","            \n","            progress.update()\n","\n","        mean_epoch_train_loss.append(np.mean(loss_train_epoch))\n","        mean_epoch_validation_loss.append(np.mean(loss_valid_epoch))\n","        \n","        wandb.log({\"mean_epoch_validation_loss\": mean_epoch_validation_loss[-1]})\n","        wandb.log({\"mean_epoch_train_loss\": mean_epoch_train_loss[-1]})\n","        \n","        progress.close()\n","        '''\n","        \n","\n","    return model\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:52:29.171875Z","iopub.status.busy":"2023-12-09T21:52:29.171570Z","iopub.status.idle":"2023-12-09T21:52:29.185909Z","shell.execute_reply":"2023-12-09T21:52:29.184963Z","shell.execute_reply.started":"2023-12-09T21:52:29.171848Z"},"trusted":true},"outputs":[],"source":["class Args():\n","    def __init__(self):\n","        self.backbone = gpt_model_name\n","        self.train_data = \"Features_train_coco_ru_vitb16_82783.pkl\"\n","        self.valid_data = \"Features_val_coco_ru_vitb16.pkl\"\n","        self.out_dir = 'checkpoints'\n","        self.prefix = '20bs_adamw'\n","        self.epochs = 1\n","        self.save_every = 1\n","        self.prefix_length = 30\n","        self.bs = 3\n","        self.only_prefix = False\n","        self.lr = 2e-5\n","        self.warmup_steps = 5000\n","args = Args()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:52:29.187499Z","iopub.status.busy":"2023-12-09T21:52:29.187189Z","iopub.status.idle":"2023-12-09T21:54:57.793198Z","shell.execute_reply":"2023-12-09T21:54:57.791218Z","shell.execute_reply.started":"2023-12-09T21:52:29.187472Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c522eed9a0e417e98db31dbbfe89190","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6d76fc9cf044064a9533a18f681c880","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5819568b6c644f239685b51ec81b6d94","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0c382fecd5d4b0ab65bc6b45bdd94f9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Data size is 414113\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 414113/414113 [02:24<00:00, 2859.25it/s]\n"]}],"source":["train_dataset = ClipCocoDataset(args.train_data, args.prefix_length, train=True)\n","#valid_dataset = ClipCocoDataset(args.valid_data, args.prefix_length, train=False)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:54:57.795504Z","iopub.status.busy":"2023-12-09T21:54:57.795086Z","iopub.status.idle":"2023-12-09T21:55:45.622141Z","shell.execute_reply":"2023-12-09T21:55:45.620922Z","shell.execute_reply.started":"2023-12-09T21:54:57.795449Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-12-09 21:54:58--  https://docs.google.com/uc?export=download&confirm=t&id=1m9kcH1k8mjTXuwNWwr9gfDpBwdBG9lWl\n","Resolving docs.google.com (docs.google.com)... 172.217.204.100, 172.217.204.138, 172.217.204.113, ...\n","Connecting to docs.google.com (docs.google.com)|172.217.204.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-0c-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ii3scoh6akvr21mp5nkh0tutelu45r2q/1702158825000/09074642392443333439/*/1m9kcH1k8mjTXuwNWwr9gfDpBwdBG9lWl?e=download&uuid=52967028-65b2-4a97-8004-11237800526b [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-12-09 21:54:59--  https://doc-0c-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ii3scoh6akvr21mp5nkh0tutelu45r2q/1702158825000/09074642392443333439/*/1m9kcH1k8mjTXuwNWwr9gfDpBwdBG9lWl?e=download&uuid=52967028-65b2-4a97-8004-11237800526b\n","Resolving doc-0c-38-docs.googleusercontent.com (doc-0c-38-docs.googleusercontent.com)... 142.251.107.132, 2607:f8b0:400c:c32::84\n","Connecting to doc-0c-38-docs.googleusercontent.com (doc-0c-38-docs.googleusercontent.com)|142.251.107.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2676011024 (2.5G) [application/zip]\n","Saving to: ‘last_weights.zip’\n","\n","last_weights.zip    100%[===================>]   2.49G   248MB/s    in 10s     \n","\n","2023-12-09 21:55:09 (248 MB/s) - ‘last_weights.zip’ saved [2676011024/2676011024]\n","\n","Archive:  last_weights.zip\n","  inflating: first_start_latest_gpt2_medium.pt  \n","  inflating: __MACOSX/._first_start_latest_gpt2_medium.pt  \n"]}],"source":["!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1m9kcH1k8mjTXuwNWwr9gfDpBwdBG9lWl' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1m9kcH1k8mjTXuwNWwr9gfDpBwdBG9lWl\" -O last_weights.zip && rm -rf /tmp/cookies.txt\n","!unzip last_weights.zip"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:55:45.627525Z","iopub.status.busy":"2023-12-09T21:55:45.627023Z","iopub.status.idle":"2023-12-09T21:56:06.764145Z","shell.execute_reply":"2023-12-09T21:56:06.763086Z","shell.execute_reply.started":"2023-12-09T21:55:45.627475Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3402d650a01408aad81457efb41ea23","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"758bfe4d9de840ddac455d68d454134d","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.config = {\n","  \"learning_rate\": args.lr,\n","  \"epochs\": args.epochs,\n","  \"batch_size\": args.bs\n","}\n","\n","\n","\n","model = ClipCaptionModel(args.prefix_length)\n","model_path = 'first_start_latest_gpt2_medium.pt'\n","model.load_state_dict(torch.load(model_path, map_location='cpu')) \n","model = model.to(device)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:56:06.765824Z","iopub.status.busy":"2023-12-09T21:56:06.765436Z","iopub.status.idle":"2023-12-09T21:56:06.773042Z","shell.execute_reply":"2023-12-09T21:56:06.772104Z","shell.execute_reply.started":"2023-12-09T21:56:06.765787Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.bs,\n","    shuffle=True,\n","    drop_last=True,\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:56:06.774554Z","iopub.status.busy":"2023-12-09T21:56:06.774277Z","iopub.status.idle":"2023-12-09T21:56:07.110089Z","shell.execute_reply":"2023-12-09T21:56:07.108765Z","shell.execute_reply.started":"2023-12-09T21:56:06.774529Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(\n","        model.parameters(),\n","        lr=args.lr,\n","    )\n","\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=args.warmup_steps,\n","    num_training_steps=args.epochs * len(train_dataloader)\n",")\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T21:56:07.111849Z","iopub.status.busy":"2023-12-09T21:56:07.111469Z","iopub.status.idle":"2023-12-09T21:56:07.852470Z","shell.execute_reply":"2023-12-09T21:56:07.851430Z","shell.execute_reply.started":"2023-12-09T21:56:07.111812Z"},"trusted":true},"outputs":[],"source":["import torch\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T00:51:36.669306Z","iopub.status.busy":"2023-12-10T00:51:36.668604Z","iopub.status.idle":"2023-12-10T00:51:36.675690Z","shell.execute_reply":"2023-12-10T00:51:36.674727Z","shell.execute_reply.started":"2023-12-10T00:51:36.669271Z"},"trusted":true},"outputs":[],"source":["sys.stdout.flush()"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T01:19:05.045770Z","iopub.status.busy":"2023-12-10T01:19:05.045243Z","iopub.status.idle":"2023-12-10T01:19:05.470160Z","shell.execute_reply":"2023-12-10T01:19:05.468627Z","shell.execute_reply.started":"2023-12-10T01:19:05.045726Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train both prefix and GPT2\n",">>> Training epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","\n","\n","20bs_adamw:   0%|          | 0/138037 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.76 GiB (GPU 0; 15.90 GiB total capacity; 11.76 GiB already allocated; 321.75 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain both prefix and GPT2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[47], line 66\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataset, train_dataloader, model, optimizer, scheduler, args, warmup_steps, output_dir, output_prefix)\u001b[0m\n\u001b[1;32m     58\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, train_dataset\u001b[38;5;241m.\u001b[39mprefix_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     60\u001b[0m loss \u001b[38;5;241m=\u001b[39m nnf\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[1;32m     61\u001b[0m     logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     62\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m     63\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 66\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     68\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.76 GiB (GPU 0; 15.90 GiB total capacity; 11.76 GiB already allocated; 321.75 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["print(\"Train both prefix and GPT2\")\n","sys.stdout.flush()\n","model = train(\n","    train_dataset,\n","    train_dataloader,\n","    model,\n","    optimizer,\n","    scheduler,\n","    args,\n","    warmup_steps=args.warmup_steps,\n","    output_dir=args.out_dir,\n","    output_prefix=args.prefix\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-09T21:23:15.964114Z","iopub.status.idle":"2023-12-09T21:23:15.964467Z","shell.execute_reply":"2023-12-09T21:23:15.964309Z","shell.execute_reply.started":"2023-12-09T21:23:15.964293Z"},"trusted":true},"outputs":[],"source":["len(\"Вопрос: что на изображении? Ответ: \")"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T00:52:42.351225Z","iopub.status.busy":"2023-12-10T00:52:42.350364Z","iopub.status.idle":"2023-12-10T00:59:18.830741Z","shell.execute_reply":"2023-12-10T00:59:18.829533Z","shell.execute_reply.started":"2023-12-10T00:52:42.351183Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: checkpoints/20bs_adamw_latest_gpt2_medium.pt (deflated 22%)\n"]}],"source":["!zip weights.zip checkpoints/20bs_adamw_latest_gpt2_medium.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":92290,"sourceId":214432,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
