{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install bitsandbytes\n!pip install ruclip==0.0.2\n!pip install transformers==4.27.4\n!pip install pycocotools\n!pip install git+https://github.com/openai/CLIP.git\n!pip install open_clip_torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-11T19:52:21.474627Z","iopub.execute_input":"2023-12-11T19:52:21.475006Z","iopub.status.idle":"2023-12-11T19:54:18.253777Z","shell.execute_reply.started":"2023-12-11T19:52:21.474979Z","shell.execute_reply":"2023-12-11T19:54:18.252787Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.38.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.3.post1)\nCollecting ruclip==0.0.2\n  Downloading ruclip-0.0.2-py3-none-any.whl (14 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from ruclip==0.0.2) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from ruclip==0.0.2) (0.15.1)\nCollecting huggingface-hub==0.2.1 (from ruclip==0.0.2)\n  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting youtokentome~=1.0.6 (from ruclip==0.0.2)\n  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting more-itertools==8.12.0 (from ruclip==0.0.2)\n  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (3.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (4.66.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.2.1->ruclip==0.0.2) (21.3)\nRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.10/site-packages (from youtokentome~=1.0.6->ruclip==0.0.2) (8.1.7)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->ruclip==0.0.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->ruclip==0.0.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->ruclip==0.0.2) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->ruclip==0.0.2) (1.24.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->ruclip==0.0.2) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub==0.2.1->ruclip==0.0.2) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->ruclip==0.0.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.2.1->ruclip==0.0.2) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->ruclip==0.0.2) (1.3.0)\nBuilding wheels for collected packages: youtokentome\n  Building wheel for youtokentome (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp310-cp310-linux_x86_64.whl size=193020 sha256=13c93391f55f4e56e3e15297fe764b1ec5564cbd7c908aad3cd1a0ac9092a424\n  Stored in directory: /root/.cache/pip/wheels/df/85/f8/301d2ba45f43f30bed2fe413efa760bc726b8b660ed9c2900c\nSuccessfully built youtokentome\nInstalling collected packages: youtokentome, more-itertools, huggingface-hub, ruclip\n  Attempting uninstall: more-itertools\n    Found existing installation: more-itertools 10.1.0\n    Uninstalling more-itertools-10.1.0:\n      Successfully uninstalled more-itertools-10.1.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.19.4\n    Uninstalling huggingface-hub-0.19.4:\n      Successfully uninstalled huggingface-hub-0.19.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npeft 0.7.0 requires huggingface-hub>=0.17.0, but you have huggingface-hub 0.2.1 which is incompatible.\ntokenizers 0.15.0 requires huggingface_hub<1.0,>=0.16.4, but you have huggingface-hub 0.2.1 which is incompatible.\ntransformers 4.35.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 0.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.2.1 more-itertools-8.12.0 ruclip-0.0.2 youtokentome-1.0.6\nCollecting transformers==4.27.4\n  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (3.12.2)\nCollecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.27.4)\n  Obtaining dependency information for huggingface-hub<1.0,>=0.11.0 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.4)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.27.4) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.4) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.4) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.27.4) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.27.4) (2023.11.17)\nDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, huggingface-hub, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.0\n    Uninstalling tokenizers-0.15.0:\n      Successfully uninstalled tokenizers-0.15.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.2.1\n    Uninstalling huggingface-hub-0.2.1:\n      Successfully uninstalled huggingface-hub-0.2.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.35.2\n    Uninstalling transformers-4.35.2:\n      Successfully uninstalled transformers-4.35.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.27.4 which is incompatible.\nruclip 0.0.2 requires huggingface-hub==0.2.1, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.19.4 tokenizers-0.13.3 transformers-4.27.4\nCollecting pycocotools\n  Obtaining dependency information for pycocotools from https://files.pythonhosted.org/packages/ba/64/0451cf41a00fd5ac4501de4ea0e395b7d909e09d665e56890b5d3809ae26/pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.24.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.7\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-sspxhg6x\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-sspxhg6x\n  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy (from clip==1.0)\n  Obtaining dependency information for ftfy from https://files.pythonhosted.org/packages/91/f8/dfa32d06cfcbdb76bc46e0f5d69c537de33f4cedb1a15cd4746ab45a6a26/ftfy-6.1.3-py3-none-any.whl.metadata\n  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2023.8.8)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.15.1)\nCollecting wcwidth<0.3.0,>=0.2.12 (from ftfy->clip==1.0)\n  Obtaining dependency information for wcwidth<0.3.0,>=0.2.12 from https://files.pythonhosted.org/packages/31/b1/a59de0ad3aabb17523a39804f4c6df3ae87ead053a4e25362ae03d73d03a/wcwidth-0.2.12-py2.py3-none-any.whl.metadata\n  Downloading wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\nBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=559204b4f6d839aad0997cc505a71cb72f1ef687bd2c7aecc3c28056de8b29ec\n  Stored in directory: /tmp/pip-ephem-wheel-cache-_6_dwrhu/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: wcwidth, ftfy, clip\n  Attempting uninstall: wcwidth\n    Found existing installation: wcwidth 0.2.6\n    Uninstalling wcwidth-0.2.6:\n      Successfully uninstalled wcwidth-0.2.6\nSuccessfully installed clip-1.0 ftfy-6.1.3 wcwidth-0.2.12\nCollecting open_clip_torch\n  Obtaining dependency information for open_clip_torch from https://files.pythonhosted.org/packages/7c/7f/952fdffa17b15d0c7c51a730860fcf4f4982528ecc753b190dcd46cc944b/open_clip_torch-2.23.0-py3-none-any.whl.metadata\n  Downloading open_clip_torch-2.23.0-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.15.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2023.8.8)\nRequirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (6.1.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (4.66.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.19.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.1.99)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (3.20.3)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.9.12)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch) (0.2.12)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2023.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (6.0.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (21.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open_clip_torch) (0.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (1.24.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\nDownloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: open_clip_torch\nSuccessfully installed open_clip_torch-2.23.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm -rf ru_capt.json\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1uIO34T8d0ML23I30mcRFAD7niggm1kIt' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1uIO34T8d0ML23I30mcRFAD7niggm1kIt\" -O ru_capt.json && rm -rf /tmp/cookies.txt","metadata":{"execution":{"iopub.status.busy":"2023-12-11T21:07:43.926332Z","iopub.execute_input":"2023-12-11T21:07:43.927331Z","iopub.status.idle":"2023-12-11T21:07:48.625156Z","shell.execute_reply.started":"2023-12-11T21:07:43.927297Z","shell.execute_reply":"2023-12-11T21:07:48.623933Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2023-12-11 21:07:45--  https://docs.google.com/uc?export=download&confirm=t&id=1uIO34T8d0ML23I30mcRFAD7niggm1kIt\nResolving docs.google.com (docs.google.com)... 74.125.195.138, 74.125.195.113, 74.125.195.139, ...\nConnecting to docs.google.com (docs.google.com)|74.125.195.138|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://doc-04-1s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ci2o65krel8g0qro6u7iqvvrqo6pe2j0/1702328850000/16206607871830480110/*/1uIO34T8d0ML23I30mcRFAD7niggm1kIt?e=download&uuid=f4b1c67f-4884-4de5-adbb-5c133509ea53 [following]\nWarning: wildcards not supported in HTTP.\n--2023-12-11 21:07:45--  https://doc-04-1s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ci2o65krel8g0qro6u7iqvvrqo6pe2j0/1702328850000/16206607871830480110/*/1uIO34T8d0ML23I30mcRFAD7niggm1kIt?e=download&uuid=f4b1c67f-4884-4de5-adbb-5c133509ea53\nResolving doc-04-1s-docs.googleusercontent.com (doc-04-1s-docs.googleusercontent.com)... 142.250.99.132, 2607:f8b0:400e:c0c::84\nConnecting to doc-04-1s-docs.googleusercontent.com (doc-04-1s-docs.googleusercontent.com)|142.250.99.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 174834387 (167M) [application/json]\nSaving to: ‘ru_capt.json’\n\nru_capt.json        100%[===================>] 166.73M  69.0MB/s    in 2.4s    \n\n2023-12-11 21:07:48 (69.0 MB/s) - ‘ru_capt.json’ saved [174834387/174834387]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm -rf train2014_emb.zip\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=11OpNsXhmtafzItkGxaTqMXqgL2dQycl6' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=11OpNsXhmtafzItkGxaTqMXqgL2dQycl6\" -O train2014_emb.zip && rm -rf /tmp/cookies.txt\n!unzip train2014_emb.zip","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:45:42.253227Z","iopub.execute_input":"2023-12-11T22:45:42.254319Z","iopub.status.idle":"2023-12-11T22:45:51.308254Z","shell.execute_reply.started":"2023-12-11T22:45:42.254286Z","shell.execute_reply":"2023-12-11T22:45:51.307115Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2023-12-11 22:45:43--  https://docs.google.com/uc?export=download&confirm=t&id=11OpNsXhmtafzItkGxaTqMXqgL2dQycl6\nResolving docs.google.com (docs.google.com)... 173.194.212.138, 173.194.212.139, 173.194.212.102, ...\nConnecting to docs.google.com (docs.google.com)|173.194.212.138|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://doc-00-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1oqr5fh4scvbfjdk5l8uiaiuvf6e7mhs/1702334700000/09074642392443333439/*/11OpNsXhmtafzItkGxaTqMXqgL2dQycl6?e=download&uuid=85a8bab5-dc93-4a52-a092-f59ccc6a4a57 [following]\nWarning: wildcards not supported in HTTP.\n--2023-12-11 22:45:43--  https://doc-00-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1oqr5fh4scvbfjdk5l8uiaiuvf6e7mhs/1702334700000/09074642392443333439/*/11OpNsXhmtafzItkGxaTqMXqgL2dQycl6?e=download&uuid=85a8bab5-dc93-4a52-a092-f59ccc6a4a57\nResolving doc-00-38-docs.googleusercontent.com (doc-00-38-docs.googleusercontent.com)... 108.177.11.132, 2607:f8b0:400c:c01::84\nConnecting to doc-00-38-docs.googleusercontent.com (doc-00-38-docs.googleusercontent.com)|108.177.11.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 215682436 (206M) [application/zip]\nSaving to: ‘train2014_emb.zip’\n\ntrain2014_emb.zip   100%[===================>] 205.69M   215MB/s    in 1.0s    \n\n2023-12-11 22:45:44 (215 MB/s) - ‘train2014_emb.zip’ saved [215682436/215682436]\n\nArchive:  train2014_emb.zip\n  inflating: Features_train_coco_ru_vitb16_82783.pkl  \n  inflating: __MACOSX/._Features_train_coco_ru_vitb16_82783.pkl  \n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm -rf val2014_emb.zip\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0\" -O val2014_emb.zip && rm -rf /tmp/cookies.txt\n!unzip val2014_emb.zip","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:45:51.310043Z","iopub.execute_input":"2023-12-11T22:45:51.310363Z","iopub.status.idle":"2023-12-11T22:45:56.842656Z","shell.execute_reply.started":"2023-12-11T22:45:51.310334Z","shell.execute_reply":"2023-12-11T22:45:56.841688Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2023-12-11 22:45:52--  https://docs.google.com/uc?export=download&confirm=t&id=1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0\nResolving docs.google.com (docs.google.com)... 173.194.211.102, 173.194.211.113, 173.194.211.139, ...\nConnecting to docs.google.com (docs.google.com)|173.194.211.102|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://doc-0s-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5kefsc4eac5b6fmp1e2dnv0r4li7ku98/1702334700000/09074642392443333439/*/1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0?e=download&uuid=74d0728d-ee07-4ca1-b3e2-60be25ca6c77 [following]\nWarning: wildcards not supported in HTTP.\n--2023-12-11 22:45:52--  https://doc-0s-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5kefsc4eac5b6fmp1e2dnv0r4li7ku98/1702334700000/09074642392443333439/*/1a-XuH0q5Ktlo6fIGFKQVkGEUkjiQ10X0?e=download&uuid=74d0728d-ee07-4ca1-b3e2-60be25ca6c77\nResolving doc-0s-38-docs.googleusercontent.com (doc-0s-38-docs.googleusercontent.com)... 108.177.11.132, 2607:f8b0:400c:c01::84\nConnecting to doc-0s-38-docs.googleusercontent.com (doc-0s-38-docs.googleusercontent.com)|108.177.11.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 105531134 (101M) [application/zip]\nSaving to: ‘val2014_emb.zip’\n\nval2014_emb.zip     100%[===================>] 100.64M   238MB/s    in 0.4s    \n\n2023-12-11 22:45:52 (238 MB/s) - ‘val2014_emb.zip’ saved [105531134/105531134]\n\nArchive:  val2014_emb.zip\n  inflating: Features_val_coco_ru_vitb16.pkl  \n  inflating: __MACOSX/._Features_val_coco_ru_vitb16.pkl  \n","output_type":"stream"}]},{"cell_type":"code","source":"#import wandb\n#wandb.login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nru_capt = {}\nwith open('./ru_capt.json', 'r') as file:\n    for st in file:\n        data = json.loads(st)\n        ru_capt[data['id']] = data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(ru_capt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as nnf\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-12-11T00:45:59.134951Z","iopub.execute_input":"2023-12-11T00:45:59.135256Z","iopub.status.idle":"2023-12-11T00:45:59.139899Z","shell.execute_reply.started":"2023-12-11T00:45:59.135230Z","shell.execute_reply":"2023-12-11T00:45:59.138985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm, trange\nimport os\nimport pickle\nimport sys\nimport argparse\nimport json\nfrom typing import Tuple, Optional, Union\nfrom torch.cuda.amp import autocast\n\nimport ruclip\nimport clip, open_clip\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:55:33.710541Z","iopub.execute_input":"2023-12-11T19:55:33.711261Z","iopub.status.idle":"2023-12-11T19:55:35.918842Z","shell.execute_reply.started":"2023-12-11T19:55:33.711219Z","shell.execute_reply":"2023-12-11T19:55:35.917966Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, sizes: Tuple[int, ...], bias=True, act=nn.Tanh):\n        super(MLP, self).__init__()\n        layers = []\n        for i in range(len(sizes) - 1):\n            layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=bias))\n            if i < len(sizes) - 2:\n                layers.append(act())\n        self.model = nn.Sequential(*layers)\n    \n    @autocast()  \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.model(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def freeze(\n    model,\n    freeze_emb=False,\n    freeze_ln=False,\n    freeze_attn=True,\n    freeze_ff=True,\n    freeze_other=False,\n):\n    \n    for name, p in model.named_parameters():\n    # freeze all parameters except the layernorm and positional embeddings\n        name = name.lower()\n        if 'ln' in name or 'norm' in name:\n            p.requires_grad = not freeze_ln\n        elif 'embeddings' in name:\n            p.requires_grad = not freeze_emb\n        elif 'mlp' in name:\n            p.requires_grad = not freeze_ff\n        elif 'attn' in name:\n            p.requires_grad = not freeze_attn\n        else:\n            p.requires_grad = not freeze_other\n           \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_path = f\"Features_train_coco_ru_vitb16_82783.pkl\"\nval_out_path = \"Features_val_coco_ru_vitb16.pkl\"\nwith open(out_path, 'rb') as f:\n    embeddings_train = pickle.load(f)\nwith open(val_out_path, 'rb') as f:\n    embeddings_val = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LAMA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft transformers bitsandbytes accelerate\n!pip install -i https://test.pypi.org/simple/ bitsandbytes\n!pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:52:07.088466Z","iopub.execute_input":"2023-12-11T22:52:07.088752Z","iopub.status.idle":"2023-12-11T22:52:46.746200Z","shell.execute_reply.started":"2023-12-11T22:52:07.088727Z","shell.execute_reply":"2023-12-11T22:52:46.745109Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/82/cc/bf022d6bc3996a5939c3ee39bde2b0e1f8bf6cea6ef9c9cdaf1639586237/peft-0.7.0-py3-none-any.whl.metadata\n  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.2)\nCollecting bitsandbytes\n  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/d9/8d/b62d4fb02587e293e5b91b68bbcaa2d88c6a0360b622e9521d4bd07a20cd/bitsandbytes-0.41.3.post2-py3-none-any.whl.metadata\n  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.7.0-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes, peft\nSuccessfully installed bitsandbytes-0.41.3.post2 peft-0.7.0\nLooking in indexes: https://test.pypi.org/simple/\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.3.post2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n\nMODEL_NAME = \"IlyaGusev/saiga2_7b_lora\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nst_time = time.time()\n\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_quant_type=\"nf4\",\n#     bnb_4bit_compute_dtype= torch.float16,\n#     bnb_4bit_use_double_quant=False,\n# )\n\n\nconfig = PeftConfig.from_pretrained(MODEL_NAME)\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    load_in_4bit = True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nmodel = PeftModel.from_pretrained(\n    model,\n    MODEL_NAME,\n    torch_dtype=torch.float16,\n    is_trainable = True\n).to(device)\n\nmodel.eval()\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\ngeneration_config = GenerationConfig.from_pretrained(MODEL_NAME)\nprint(generation_config)\nprint(f'Прошло времени {time.time() - st_time}')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:53:07.494963Z","iopub.execute_input":"2023-12-11T22:53:07.495349Z","iopub.status.idle":"2023-12-11T22:53:12.675802Z","shell.execute_reply.started":"2023-12-11T22:53:07.495316Z","shell.execute_reply":"2023-12-11T22:53:12.674525Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/371 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bd88fd37c3446689d1c5de14684313b"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m st_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# bnb_config = BitsAndBytesConfig(\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     load_in_4bit=True,\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     bnb_4bit_quant_type=\"nf4\",\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     bnb_4bit_compute_dtype= torch.float16,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     bnb_4bit_use_double_quant=False,\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mPeftConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     21\u001b[0m     config\u001b[38;5;241m.\u001b[39mbase_model_name_or_path,\n\u001b[1;32m     22\u001b[0m     load_in_4bit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     24\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     27\u001b[0m     model,\n\u001b[1;32m     28\u001b[0m     MODEL_NAME,\n\u001b[1;32m     29\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     30\u001b[0m     is_trainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/config.py:134\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     config_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    133\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclass_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloaded_attributes}\n\u001b[0;32m--> 134\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n","\u001b[0;31mTypeError\u001b[0m: LoraConfig.__init__() got an unexpected keyword argument 'enable_lora'"],"ename":"TypeError","evalue":"LoraConfig.__init__() got an unexpected keyword argument 'enable_lora'","output_type":"error"}]},{"cell_type":"code","source":"CUTOFF_LEN = 3584\n\ndef generate_prompt(data_point):\n    promt = f\"\"\"<s>system\n{data_point['system']}</s><s>user\n{data_point['user']}</s><s>bot\n{data_point['bot']}</s>\"\"\"\n    #     print(promt)\n    return promt\n \n    \ndef tokenize (prompt, add_eos_token=True):\n    result = tokenizer(\n        prompt,\n        truncation=True,\n        max_length=CUTOFF_LEN,\n        padding=False,\n        return_tensors=None,\n    )\n    if (\n        result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < CUTOFF_LEN\n        and add_eos_token\n    ):\n        \n        result[\"input_ids\"].append(tokenizer.eos_token_id)\n        result[\"attention_mask\"].append(1)\n        \n        \n    \n    result[\"labels\"] = result[\"input_ids\"].copy()\n\n    return result\n \ndef generate_and_tokenize_prompt(data_point):\n    full_prompt = generate_prompt(data_point)\n    tokenized_full_prompt = tokenize(full_prompt)\n#     print(tokenized_full_prompt)\n    return tokenized_full_prompt","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:38.761201Z","iopub.execute_input":"2023-12-11T22:46:38.761851Z","iopub.status.idle":"2023-12-11T22:46:38.769724Z","shell.execute_reply.started":"2023-12-11T22:46:38.761820Z","shell.execute_reply":"2023-12-11T22:46:38.768819Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Тест датасета\n\nfrom datasets import Dataset\n\ntrain_dataset = Dataset.from_dict({\"system\": [\"Что на картинке\"] * 1000,\n                                   \"user\": all_data[\"clip_embedding\"][:1000],\n                                   \"bot\": my_data_captions[:1000]})\n\nvalidation_dataset = Dataset.from_dict({\"system\": [\"Что на картинке\"] * 1000,\n                                        \"user\": all_data_val[\"clip_embedding\"][:1000],\n                                        \"bot\": my_data_captions_val[:1000]})\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:42.221418Z","iopub.execute_input":"2023-12-11T22:46:42.221749Z","iopub.status.idle":"2023-12-11T22:46:43.224003Z","shell.execute_reply.started":"2023-12-11T22:46:42.221725Z","shell.execute_reply":"2023-12-11T22:46:43.223027Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = (\n    train_dataset.map(generate_and_tokenize_prompt)\n)\n\nval_data = (\n    validation_dataset.map(generate_and_tokenize_prompt)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:44.704113Z","iopub.execute_input":"2023-12-11T22:46:44.704634Z","iopub.status.idle":"2023-12-11T22:48:10.834818Z","shell.execute_reply.started":"2023-12-11T22:46:44.704605Z","shell.execute_reply":"2023-12-11T22:48:10.833861Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55eed4df51374ee693bd4967dbfd2d83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c845fb99ede4d199db6236f4b428071"}},"metadata":{}}]},{"cell_type":"code","source":"columns_to_remove = ['system', 'user', 'bot']\ntrain_data = train_data.remove_columns(columns_to_remove)\nval_data = val_data.remove_columns(columns_to_remove)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:48:10.836509Z","iopub.execute_input":"2023-12-11T22:48:10.836789Z","iopub.status.idle":"2023-12-11T22:48:10.845031Z","shell.execute_reply.started":"2023-12-11T22:48:10.836765Z","shell.execute_reply":"2023-12-11T22:48:10.844105Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:10:35.872479Z","iopub.execute_input":"2023-12-11T22:10:35.872864Z","iopub.status.idle":"2023-12-11T22:10:35.879225Z","shell.execute_reply.started":"2023-12-11T22:10:35.872833Z","shell.execute_reply":"2023-12-11T22:10:35.878272Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"len(train_data[0]['input_ids']), len(train_data[0]['attention_mask']), len(train_data[0]['labels'])","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:10:43.479241Z","iopub.execute_input":"2023-12-11T22:10:43.480130Z","iopub.status.idle":"2023-12-11T22:10:43.507213Z","shell.execute_reply.started":"2023-12-11T22:10:43.480094Z","shell.execute_reply":"2023-12-11T22:10:43.506335Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(3584, 3584, 3584)"},"metadata":{}}]},{"cell_type":"code","source":"pip install transformers==4.35.2","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:48:10.846975Z","iopub.execute_input":"2023-12-11T22:48:10.847305Z","iopub.status.idle":"2023-12-11T22:48:22.522107Z","shell.execute_reply.started":"2023-12-11T22:48:10.847281Z","shell.execute_reply":"2023-12-11T22:48:22.520876Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==4.35.2 in /opt/conda/lib/python3.10/site-packages (4.35.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.35.2) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (2023.11.17)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# тут начинается обучение сайги, пока не пробовал\nimport transformers\n\nBATCH_SIZE = 1\nMICRO_BATCH_SIZE = 1\nGRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\nLEARNING_RATE = 3e-4\nTRAIN_STEPS = 100\nOUTPUT_DIR = \"/kaggle/working/tmp\"\n\ntraining_arguments = transformers.TrainingArguments(\n            remove_unused_columns=False,\n            per_device_train_batch_size=MICRO_BATCH_SIZE,\n            gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n#             warmup_steps=200,\n            max_steps=TRAIN_STEPS,\n            learning_rate=LEARNING_RATE,\n            fp16=True,\n            logging_steps=10,\n            optim=\"adamw_torch\",\n            evaluation_strategy=\"steps\",\n            save_strategy=\"steps\",\n            eval_steps=10,\n            save_steps=10,\n            output_dir=OUTPUT_DIR,\n            save_total_limit=10,\n            load_best_model_at_end=True,\n            report_to=None,\n            overwrite_output_dir=True, # Overwrite the content of the output dir\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:48:22.524297Z","iopub.execute_input":"2023-12-11T22:48:22.524618Z","iopub.status.idle":"2023-12-11T22:48:22.554050Z","shell.execute_reply.started":"2023-12-11T22:48:22.524589Z","shell.execute_reply":"2023-12-11T22:48:22.553314Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# c5ae028d4beaea1eeb875f10d0f8ba4f31e45135","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = transformers.DataCollatorForSeq2Seq(\n    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n)\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    args=training_arguments,\n    data_collator=data_collator\n)\nmodel = torch.compile(model)\ntrainer.train()\nmodel.save_pretrained(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:48:40.695649Z","iopub.execute_input":"2023-12-11T22:48:40.696034Z","iopub.status.idle":"2023-12-11T22:49:48.611658Z","shell.execute_reply.started":"2023-12-11T22:48:40.696004Z","shell.execute_reply":"2023-12-11T22:49:48.609835Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231211_224912-zx04g970</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nas-clip/huggingface/runs/zx04g970' target=\"_blank\">wise-planet-10</a></strong> to <a href='https://wandb.ai/nas-clip/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nas-clip/huggingface' target=\"_blank\">https://wandb.ai/nas-clip/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nas-clip/huggingface/runs/zx04g970' target=\"_blank\">https://wandb.ai/nas-clip/huggingface/runs/zx04g970</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      7\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcompile(model)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(OUTPUT_DIR)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:680\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:668\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:1071\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward in MPTForCausalLM does not support inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\n\u001b[1;32m   1062\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1063\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1069\u001b[0m         )\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:108\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1034\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1031\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:922\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         use_cache,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:672\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:406\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(query_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    407\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1845\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1843\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.53 GiB (GPU 0; 15.90 GiB total capacity; 13.48 GiB already allocated; 1.35 GiB free; 13.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.53 GiB (GPU 0; 15.90 GiB total capacity; 13.48 GiB already allocated; 1.35 GiB free; 13.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"del trainer","metadata":{"execution":{"iopub.status.busy":"2023-12-11T20:05:29.639610Z","iopub.execute_input":"2023-12-11T20:05:29.639980Z","iopub.status.idle":"2023-12-11T20:05:29.682468Z","shell.execute_reply.started":"2023-12-11T20:05:29.639949Z","shell.execute_reply":"2023-12-11T20:05:29.681192Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\n","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"],"ename":"NameError","evalue":"name 'trainer' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Args():\n    def __init__(self):\n        self.backbone = gpt_model_name\n        self.train_data = \"Features_train_coco_ru_vitb16_82783.pkl\"\n        self.valid_data = \"Features_val_coco_ru_vitb16.pkl\"\n        self.out_dir = 'checkpoints'\n        self.prefix = '20bs_adamw'\n        self.epochs = 5\n        self.save_every = 1\n        self.prefix_length = 30\n        self.bs = 2\n        self.only_prefix = False\n        self.lr = 2e-5\n        self.warmup_steps = 5000\nargs = Args()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ClipCocoDataset(args.train_data, args.prefix_length, train=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"Features_train_coco_ru_vitb16_82783.pkl\", 'rb') as f:\n    all_data = pickle.load(f)\nprint(\"Data size is %0d\" % len(all_data[\"clip_embedding\"]))\n\nwith open(\"Features_val_coco_ru_vitb16.pkl\", 'rb') as f:\n    all_data_val = pickle.load(f)\nprint(\"Data size is %0d\" % len(all_data_val[\"clip_embedding\"]))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:04.016571Z","iopub.execute_input":"2023-12-11T22:46:04.017018Z","iopub.status.idle":"2023-12-11T22:46:06.889356Z","shell.execute_reply.started":"2023-12-11T22:46:04.016971Z","shell.execute_reply":"2023-12-11T22:46:06.888409Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Data size is 414113\nData size is 202626\n","output_type":"stream"}]},{"cell_type":"code","source":"len(all_data[\"clip_embedding\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:07.618482Z","iopub.execute_input":"2023-12-11T22:46:07.618844Z","iopub.status.idle":"2023-12-11T22:46:07.628204Z","shell.execute_reply.started":"2023-12-11T22:46:07.618815Z","shell.execute_reply":"2023-12-11T22:46:07.627371Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"414113"},"metadata":{}}]},{"cell_type":"code","source":"all_data[\"clip_embedding\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-11T21:08:09.150365Z","iopub.execute_input":"2023-12-11T21:08:09.150792Z","iopub.status.idle":"2023-12-11T21:08:09.213972Z","shell.execute_reply.started":"2023-12-11T21:08:09.150758Z","shell.execute_reply":"2023-12-11T21:08:09.212962Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.3242,  0.0470, -0.6146,  ...,  0.3919, -0.5427,  0.6181],\n        [ 0.3242,  0.0470, -0.6146,  ...,  0.3919, -0.5427,  0.6181],\n        [ 0.3242,  0.0470, -0.6146,  ...,  0.3919, -0.5427,  0.6181],\n        ...,\n        [-0.2825,  0.4247, -0.0598,  ..., -0.5093, -0.3009, -0.2749],\n        [-0.2825,  0.4247, -0.0598,  ..., -0.5093, -0.3009, -0.2749],\n        [-0.2825,  0.4247, -0.0598,  ..., -0.5093, -0.3009, -0.2749]],\n       device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"my_data_captions = [i.replace(\"Вопрос: что на изображении? Ответ: \", \"\") for i in all_data[\"captions\"]]","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:13.055318Z","iopub.execute_input":"2023-12-11T22:46:13.055646Z","iopub.status.idle":"2023-12-11T22:46:13.273327Z","shell.execute_reply.started":"2023-12-11T22:46:13.055623Z","shell.execute_reply":"2023-12-11T22:46:13.272488Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"my_data_captions_val = [i.replace(\"Вопрос: что на изображении? Ответ: \", \"\") for i in all_data_val[\"captions\"]]","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:46:16.249723Z","iopub.execute_input":"2023-12-11T22:46:16.250590Z","iopub.status.idle":"2023-12-11T22:46:16.359485Z","shell.execute_reply.started":"2023-12-11T22:46:16.250556Z","shell.execute_reply":"2023-12-11T22:46:16.358525Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"my_data_captions","metadata":{"execution":{"iopub.status.busy":"2023-12-11T22:04:25.043196Z","iopub.execute_input":"2023-12-11T22:04:25.043571Z","iopub.status.idle":"2023-12-11T22:04:25.075269Z","shell.execute_reply.started":"2023-12-11T22:04:25.043543Z","shell.execute_reply":"2023-12-11T22:04:25.074487Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['Приготовление блюд из брокколи и хлеба.',\n 'Еда подается в ярко раскрашенных пластиковых травах.',\n 'есть контейнеры, наполненные различными видами продуктов питания',\n 'Красочные блюда из мяса, овощей, фруктов и хлеба.',\n 'Куча предателей, у которых разная еда.',\n 'Жираф, поедающий пищу с верхушки дерева.',\n 'Жираф, стоящий рядом с деревом',\n 'Мать-жираф с ребенком в лесу.',\n 'Два жирафа, стоящие на площади, заполненной деревьями.',\n 'Жираф, стоящий рядом с лесом, заросшим деревьями.',\n 'На веранде стоит цветочная ваза.',\n 'Белая ваза с разноцветными цветами, сидящими внутри нее.',\n 'белая ваза со множеством цветов на сцене',\n 'Белая ваза, наполненная разноцветными цветами.',\n 'Ваза с красными и белыми цветами снаружи в солнечный день.',\n 'Зебра на пышной зеленой траве в поле.',\n 'Зебра опустилась на землю, где трава.',\n 'Зебра ест траву на солнце.',\n 'Одинокая зебра, сидящая в какой-то зеленой траве.',\n 'Зебра, сидящая на траве в зеленом открытом поле.',\n 'Женщина в купальном костюме, держащая зонтик в солнечный день.',\n 'Женщина позирует перед камерой, держа в руках розовую открытую пуговицу и в ярком, цветочном, ржавом купальном костюме, рядом со спасательным постом с озером, зелеными деревьями и голубым небом с несколькими облаками сзади.',\n 'Женщина в цветочном купальнике держит розовую пумберу.',\n 'Женщина с амбразурой у моря',\n 'Девушка в купальном костюме с розовой пуговицей.',\n 'Пару мужчин, верхом верхом на лошадях по зеленому полю.',\n 'две лошади и их всадники на траве',\n 'Два человека сидят на лошадях, которые запряжены назад.',\n 'Пара лошадей, выполняющих трюки в поле.',\n 'Два верховых всадника в костюмах заставляют своих лошадей стоять на задних лапах.',\n 'Они храбры, катаясь в джунглях на этих слонах.',\n 'НЕКОТОРЫЕ НАСЕЛЕНЫ В ДВУХ ДВУХ ЭЛЛИХАНТАХ',\n 'Некоторые люди, которые верхом на слонах.',\n 'Есть люди, которые катаются на слонах посреди леса',\n 'Несколько слонов в джунглях, несущих людей на спинах',\n 'черно-серебряная башня с часами на перекрестке возле дерева',\n 'Часы сидят на черном столбе рядом с деревом на тротуаре рядом с пешеходным переходом.',\n 'Столб с часами, показывающими 6: 10 на белой машине.',\n 'Часы видны перед высоким деревом.',\n 'Очень красивые часы на обочине дороги.',\n 'Поезд, приближающийся к остановке на путях вне стороны.',\n 'Очень длинный поезд идет по путям.',\n 'Пассажирский поезд скользит по изгибу на внешнем пути.',\n 'Поезд, идущий по рельсам в городе.',\n 'Двигатель поезда, перевозящий много телег по рельсам.',\n 'Пару жирафов, нахмурившихся друг с другом в лесу.',\n 'Пару жирафов, стоящих рядом с деревьями.',\n 'Два Зебры, кажется, в дикой природе.',\n 'Два жирафа висят рядом с деревьями и прижимаются друг к другу.',\n 'Два жирафа, кажется, обнимают друг друга.',\n 'Молодой человек катается на скейтборде в воздухе.',\n 'группа подростков, прыгающих с трамплина на скейтбордах',\n 'Изображение парня на скейтборде.',\n 'Группа мальчишек, исполняющих скейтборд-трюк на рэпе с Фиффити на нем',\n 'некоторые мужчины-скейтбордисты делают какие-то трюки и прыгают с парашютом',\n 'Зажженная свеча сова сидит рядом с часами.',\n 'Белые часы, сидящие рядом со статуей совы.',\n 'крупным планом часы рядом с подсвечником для филин',\n 'Старинные часы рядом с совой со свечой в руке.',\n 'Сова свеча и часы, сидящие перед стеной.',\n 'Большой самолет, летящий в большом голубом небе',\n 'Крупный, двухмоторный, четырехмоторный авиалайнер в полете.',\n 'Реактивный самолет AirFrance летит в небе',\n 'Большой самолет с AirFrance на борту.',\n 'Самолет Air France в середине полета.',\n 'Мужчина на мотоцикле через лес.',\n 'Мужчина, сидящий на мотоцикле в лесу.',\n 'Молодой человек ездит на очень старом велосипеде.',\n 'Человек смотрит на что-то свысока, сидя на велосипеде.',\n 'Мужчина на старомодном велосипеде по волнам',\n 'Печь с печью на вершине на кухне.',\n 'Печка с зажженным капюшоном на кухне.',\n 'Над отполированной верхушкой печи горит небольшой свет.',\n 'Гладкая верхняя стойка с выхлопным вентилятором с включенным светом.',\n 'Поверхность печи очищается набором ножей на стене.',\n 'Белая тарелка с коричнево-белой глазурью.',\n 'Кусок шоколадного торта на белой тарелке.',\n 'шоколадный торт и готовая к употреблению вилка',\n 'Шоколадное десерт на тарелке с вилкой.',\n 'Кусок шоколада на тарелке с салфеткой и вилкой.',\n 'Есть улица, усеянная переполненными зданиями',\n 'Машина едет по улице со зданиями по обе стороны.',\n 'Уличный знак и машина на дороге.',\n 'This is a view of a quaint city street.',\n 'Городская улица с табличкой \"Отель Peace Way\".',\n 'Скейт-парк рядом с водоемом и зеленым парком.',\n 'Вид с неба на прогулочную дорожку вдоль берега реки.',\n 'Широкая прогулочная дорожка позволяет прогуляться вдоль реки.',\n 'Набережная и сад рядом с рекой.',\n 'какая-то трава и человек в синей рубашке, выгуливающий собаку и воду',\n 'Женщина резала пиццу вилкой и ножом, сидя рядом с молодой девушкой',\n 'Женщина и ребенок сидят за столом с пиццей перед собой.',\n 'Дама с ребенком сидят. Дама режет кусочки пиццы.',\n 'Женщина режет пиццу вилкой и ножом.',\n 'Женщина резала пиццу вилкой и ножом',\n 'мужчина и женщина, нарезанные на большой торт',\n 'Мужчина и женщина, стоящие перед тортом.',\n 'Женщина, которая режет торт.',\n 'два человека, стоящие возле стола с тортом',\n 'Женщина режет торт, а мужчина стоит за ней',\n 'Кусок торта и кофе лежат на открытом столе.',\n 'Кусочек торта рядом с большой наполненной чашкой на деревянном столе.',\n 'Десерт и чашка кофе сидят рядом с книгой и кошельком.',\n 'Кусок торта и кружка, сидящие на деревянном столе снаружи.',\n 'крупным планом кусок торта на тарелке',\n 'Кухня имеет странно выглядящие цвета в ней.',\n 'Изображение кухни, которое содержит меньшие фотографии предметов внутри этой кухни.',\n 'Трехмерный рендеринг кухонной зоны с различными вариантами отделки.',\n 'Серия фотографий крошечной модельной кухни',\n 'Коллаж фотографий с чистой ржавой кухни.',\n 'Тарелка с кусочком хлеба, спреем из темного шоколада, бананами и коробкой из-под шелка.',\n 'На тарелке лежит порезанный банан с верхушкой десерта.',\n 'На хлебе - тарелка банана и шоколада',\n 'крупным планом тарелку с желе и банановым бутербродом',\n 'хлеб с банановым молоком и нутеллой на столе',\n 'Три жирафа застряли за забором зоопарка.',\n 'Три жирафа, стоящие в проруби в районе.',\n 'пара жирафов съедает немного еды из трюфеля',\n 'Два жирафа едят вместе из трости в зарослях.',\n 'несколько жирафов рядом друг с другом',\n 'Люди собрались на большом поле в пасмурный день',\n 'Люди летают котятами на поле средней школы.',\n 'Люди летают котятами в поле в пасмурный день.',\n 'Множество котят, летающих по полю людьми.',\n 'куча людей на травяном поле',\n 'Стоп-знак направляет пешеходов, когда мимо проезжает поезд.',\n 'Стоп-знак стоит посреди леса.',\n 'Стоп-знак, сидящий рядом с высокими деревьями.',\n 'Мужчина высунулся из машины возле знака короткой остановки в лесу.',\n 'Стоп-сигнал показан рядом с землей.',\n 'три зебры, стоящие в густом поле и идущие',\n 'Три зебры стоят на открытом поле.',\n 'Три зебры идут по траве поля.',\n 'Три зебры, стоящие на дьявольском поле.',\n 'Три зебры на зеленой лужайке.',\n 'женщина в военной форме порезала бизнесмену галстук на шее',\n 'Женщина в солдатской форме притворяется, что режет галстук мужчине огромной парой ножниц.',\n 'Забавная фотография женщины с большой парой ножниц, пытающейся разрезать мужской галстук.',\n 'Женщина-солдат, держащая в руках пару гигантских ножниц к чьему-то галстуку.',\n 'Мужчина в костюме и женщина в военной форме.',\n 'маленькая пицца на белой тарелке',\n 'Маленькая пицца, сидящая на белой тарелке с разными оттенками.',\n 'Пицца нагружена множеством тарелок.',\n 'На дисплее показана небольшая пицца личного размера.',\n 'Экзотическая пицца сидит на тарелке, сверху сыр и кусочки мяса.',\n 'Шесть сноубордов застряли в снегу на рельсах.',\n 'Пять скейтбордистов на стойке в заснеженной горе',\n 'Есть скейтбордисты, опирающиеся на металлический прут.',\n 'Ряды снежных досок, торчащих из снега.',\n 'Сноуборды торчат в снегу у стойки',\n 'небольшой самолет, который стоит на взлетно-посадочной полосе',\n 'самолет сидит на взлетно-посадочной полосе в ожидании взлета',\n 'Небольшой самолет с сертификатом на пропеллерах.',\n 'Красно-бело-синий вертолет имеет бирку на одном флаге.',\n 'Небольшой моторный самолет, сидящий на летном поле.',\n 'Уличный знак на столбе на улице.',\n 'Два зеленых и белых уличных указателя со зданием на заднем плане.',\n 'Городская улица имеет знак пересечения на столбе.',\n 'Уличные указатели возле высоких зданий на углу Гринвич-стрит и Вези-стрит',\n 'На столбе висят таблички \"Гринвич-стрит\" и \"Вези-стрит\".',\n 'Женщина, прислонившаяся к багажнику.',\n 'Ждет женщина с кофтой, набитой чемоданами.',\n 'Женщина рядом с колючей проволокой на автобусной остановке.',\n 'женщина стоит со своим ребенком',\n 'Женщина в желтой рубашке, стоящая рядом со мной.',\n 'Пару слонов, стоящих рядом.',\n 'Один взрослый и один маленький слон в сухой партии.',\n 'Взрослый слон толкает маленького слона ногой.',\n 'Пару слонов, играющих друг с другом в перо.',\n 'Детеныш слона пытается забраться на вершину другого слона.',\n 'Собака играет с игрушкой в траве',\n 'Собака, которая стоит в траве рядом с фрисби.',\n 'Колли, гоняющиеся за фрисби в траве.',\n 'Симпатичная собака в траве с фрисби.',\n 'Коричнево-белая собака, преследующая сине-желтого фрисби.',\n 'народ пьет вино на дегустации.',\n 'Группа людей, дегустирующих вино рядом с бочками.',\n 'Люди собираются вокруг человека, дегустирующего вино.',\n 'Мужчина наливал вино из бочек для покровителей',\n 'Люди собираются за столом, пока пьют вино.',\n 'Чучело медведя, лежащего в траве.',\n 'На зеленой траве рядом с собакой лежит плюшевый медведь.',\n 'Собака стоит в траве рядом с чучелом медведя.',\n 'Маленький бурый медведь, лежащий в траве.',\n 'плюшевый медведь лежит на лапе, а за ним стоит собака.',\n 'Большая группа слонов, пересекающих проселочную дорогу.',\n 'Детеныш слона ходит по лесу с пятью взрослыми слонами.',\n 'Стадо слонов, бегущее с младенцем.',\n 'Стадо слонов, в том числе маленький слоненок, переходит дорогу.',\n 'Четыре больших слона наблюдают за своим детенышем в дикой природе.',\n 'На песчаном пляже замерзают женщины в купальниках.',\n 'Толпы людей сидят на пляже в песке.',\n 'люди на пляже под пумбреллами',\n 'Женщины идут к местам на пляже.',\n 'Люди загорают и сидят под зонтиками на городском пляже.',\n 'Крупным планом пластиковый контейнер с хот-догами',\n 'В контейнерах находятся два хот-дога с приправами и стейк-бутерброд.',\n 'Два контейнера для пенополистирола, один с супом из стейка с перцем халапеньо, а другой с двумя хот-догами.',\n 'Суббутерброд в коробке рядом с двумя хот-догами.',\n 'два пластиковых контейнера с бутербродом и хот-догами',\n 'Мужчина поет апельсиновый фрисби на вершине пышного зеленого поля.',\n 'мужчина, стоящий во дворе с красным фрисби',\n 'Полный вид человека, бросающего фрисби.',\n 'Ночью человек бросает фрисби.',\n 'Человек, играющий с летающим красным диском на улице вечером.',\n 'Мужчина с бокалом вина на боку.',\n 'Мужчина наклоняет бокал вина в сторону.',\n 'Человек, держащий частично заполненный бокал вина.',\n 'мужчина в белой рубашке держит бокал вина',\n 'Мужчина подсказывает прозрачный бокал вина, чтобы наблюдать за его макияжем.',\n 'Еда в миске с морковкой и напитки вокруг нее',\n 'Тарелка еды: мясо, лапша, оладьи, морковь и салат',\n 'Здоровые продукты, используемые для создания обеденного блюда.',\n 'Азиатская лапша, нарезанный яичный рулет с зеленью и морковью в белой миске.',\n 'Чаша пасты, морковь, яичный рулет и капуста.',\n 'Пассажирский поезд остановился на станции.',\n 'Старый поезд едет по путям под мостом.',\n 'Одинокий поезд стоит на рельсах под мостом.',\n 'Бело-оранжевый поезд, проходящий мимо деревьев и фонаря.',\n 'Прицеп сидит под мостом и линиями электропередач.',\n 'Мальчик, играющий в футбол на футбольном поле',\n 'Группа детей, играющих в футбол на поле.',\n 'Маленький ребенок в футбольной форме пинает желтый мяч.',\n 'Молодой человек пинает футбольный мяч по полю.',\n 'Есть несколько молодых парней, практикующих футбол, некоторые со своими папами.',\n 'Маленькая девочка держит в руке мокрую брокколи.',\n 'Маленький ребенок счастливо держит свежую струю.',\n 'Маленькая девочка держит руку, полную мокрых брокколи.',\n 'Маленькая девочка держит кусок брокколи перед камерой.',\n 'маленький малыш держится за овощи',\n 'пейзаж заснеженной горы с лыжной трассой в снегу',\n 'Мужчина катался на лыжах по заснеженному склону.',\n 'Высокая гора снега с лыжами на беговой дорожке.',\n 'На снимке с расстояния видны скользящие снежные горки, частично затененные, с лыжными принтами, уходящими вдаль, а на переднем плане - одинокий скейтер.',\n 'Фотография горного склона с человеком на лыжах на переднем плане.',\n 'Гостиная, заполненная мебелью и окнами, покрытыми занавеской.',\n 'Гостиная с диваном, журнальным столиком и двумя большими окнами с белыми шторами.',\n 'гостиная с белыми шторами и черным диваном и столом',\n 'Это гостиная с белыми шторами.',\n 'Гостиная с диваном, журнальным столиком и двумя окнами.',\n 'Человек с бородой и зеленым галстуком.',\n 'Этот человек очень рад быть на собрании.',\n 'Женщина, стоящая в большой группе людей возле лестницы.',\n 'Мужчина улыбается в зеленом галстуке на шее рядом с толпой людей.',\n 'Мужчина с длинной серой бородой в белой рубашке и зеленом галстуке в пабе, полном зелено-серых покровителей.',\n 'Белая собака с фиолетовым фрисби во рту.',\n 'Белая собака держит фрисби во рту в ожидании игры.',\n 'Белая собака с фиолетовым фрисби на лацкане.',\n 'У белой собаки во рту фиолетовый фрисби.',\n 'собака держит фрисби, стоящую на траве',\n 'пару лодок, которые находятся в какой-то воде',\n 'Показана пара лодок, прикованных к щипцу.',\n 'Три лодки погрузились в неподвижную воду с облаками в небе.',\n 'В пасмурный день сплавляются три лодки.',\n 'несколько разноцветных лодок, сидящих рядом с причалом',\n 'Два человека играют в теннис в соседнем парке.',\n 'Два человека на теннисном корте играют в теннис',\n 'Два человека на общественном теннисном корте; один подает мяч.',\n 'Теннисист, качающийся на мяче',\n 'два человека, играющих в теннис на теннисном корте.',\n 'Теннисист в действии на корте.',\n 'мужчина в белой рубашке играет в теннис',\n 'человек, играющий в теннис на корте',\n 'Теннисист мужского пола бьет мяч по травяному корту.',\n 'Мужчина в движении ударил теннисный мяч теннисным рейнджером по теннисному корту.',\n 'Человек пожимает большой палец, держа в руках кусок пищи.',\n 'есть человек, сидящий и пожимающий пальцами',\n 'Мужчина ест рулет и жалеет большой палец.',\n 'Мужчине нравится большой палец с арахисовой палочкой хлеба в руке.',\n 'Человек в очках, съедающий кусочек пищи.',\n 'Разнообразие пончиков и пирожков в коробке.',\n 'Большая коробка с разными видами пончиков.',\n 'Коробка шоколада, наполненная сметаной.',\n 'Коробка, полная пончиков в разных цветах и вкусах.',\n 'Разнообразные пирожные отображаются в коробке для вынимания.',\n 'Кошка лежит на спине у мужчины на коленях.',\n 'Кошка сидит с животом на коленях у человека.',\n 'Кошка лежит на спине, сидя на чьих-то коленях.',\n 'Человек, сидящий на диване с лежащей на спине кошкой.',\n 'Кошка, лежащая на коленях и сидящая на диване',\n 'стоящая женщина с пультом в руке',\n 'Женщина с пультом в правой руке.',\n 'Женщина стоит с пультом Wii в руке.',\n 'Женщина, играющая в видеоигру в помещении.',\n 'Женщина, стоящая в комнате с пультом дистанционного управления.',\n 'Свежий сыр и пицца на белой тарелке',\n 'Пицца с зелеными листьями подается на тарелке',\n 'Небольшая пицца на белой тарелке.',\n 'Пицца, сидящая на белой тарелке рядом со стаканом воды.',\n 'пицца маргерита, подаваемая на тарелке',\n 'Школьный автобус из Лос-Анджелеса припарковался на парковке.',\n 'желтый школьный автобус припарковался на парковке',\n 'Старый желтый школьный автобус припаркован во многих местах.',\n 'Желтый автобус без пассажиров, стоящий на дороге.',\n 'На парковке показан желтый автобус.',\n 'Собака стоит рядом с скейтбордистом, прислоненным к стене.',\n 'Собака, стоящая на полу из твердого дерева рядом со стеной со своей тенью.',\n 'Собака, стоящая рядом со скейтбордом на стене.',\n 'Дог и скейтборд в комнате и тень собаки и человека на стене.',\n 'Собака смотрит на кого-то в комнате.',\n 'Несколько нафаршированных игрушечных собак собрались вместе.',\n 'белый фаршированный медведь находится в комнате',\n 'Этот медведь - мягкий, пушистый приз, который дети хотят выиграть на летнем карнавале.',\n 'Игрушечная поморская собака на сумке для игр и развлечений.',\n 'Одурманенные животные висят на столбах в воздухе.',\n 'Живописный вид на заснеженную гору и облака.',\n 'Снег на холме, возвышающемся над горами.',\n 'Солнце заглядывает сквозь облака на вершину заснеженной горы.',\n 'Поле, покрытое снегом на вершине холма.',\n 'Знак стоит на заснеженном склоне под облачным небом.',\n 'Мужчина, держащийся за руки, сидя на лавочке.',\n 'Человек сидит на скамейке с рукотворным водопадом за спиной.',\n 'Пожилой мужчина, сидящий на лавочке перед водопадом',\n 'Старик сидит на парковой скамье рядом с дураком',\n 'Человек, сидящий на коричневой скамье перед дураком.',\n 'Кровать в старом стиле с крестиком на голове',\n 'Кровать покрыта золотым декоративным покрытием.',\n 'спальная комната, заполненная старинной тканью, похожей на простыни',\n 'Очень большая и причудливо выглядящая комната с большой красивой кроватью.',\n 'Это кровать в чьей-то спальне в их доме.',\n 'Мужчина на велосипеде с рыжеволосой женщиной на коленях.',\n 'Всадник садится на велосипед с женщиной на коленях.',\n 'Мужчина на мотоцикле с красивой женщиной на коленях.',\n 'Мотоциклист и женщина позируют на велосипеде для фотографии.',\n 'Парень и девушка обнимаются на велосипеде.',\n 'Люди, играющие в теннис на корте в солнечный день',\n 'Широкий снимок группы, играющей в теннис на корте.',\n 'Группа людей, играющих в теннис на открытом воздухе',\n 'Два теннисных корта имеют парные игры, играя на них.',\n 'группа людей на теннисном корте, играющая в теннис',\n 'Мужчина стоит рядом с большим красным автобусом.',\n 'Два человека, стоявшие у разбитого школьного автобуса',\n 'Мужчина стоит рядом с красным автобусом на улице',\n 'Мужчина и две женщины разделяются на две разноцветные группы.',\n 'Мужчина, стоящий перед красным и черным школьным автобусом.',\n 'Самолет, сидящий посреди города.',\n 'Самолет на мосту через шоссе.',\n 'Крупный реактивный самолет, взлетающий со взлетно-посадочной полосы аэропорта.',\n 'Очень большой реактивный самолет JAL задел взлетно-посадочную полосу в аэропорту в городской среде',\n 'Самолет JAL выкатился за пределы взлетно-посадочной полосы в городе.',\n 'Люди собираются вокруг, когда человек садится в старый самолет.',\n 'Мужчины стоят перед опорным самолетом, а один человек фактически стоит в зоне водителя и держится за верхнее крыло.',\n 'Группа людей, стоящих вокруг самолета.',\n 'большая группа людей стояла рядом с очень старым самолетом',\n 'Несколько человек стоят и смотрят на винтажный самолет.',\n 'Ванная комната CGI с овальной ванночкой, заполненной водой.',\n 'Раковина большой современной ванной комнаты наполнена водой.',\n 'ванная комната с ванночкой, туалетом и стоячим душем',\n 'Это ванная комната с джакузи, душем, раковиной и туалетом.',\n 'Компьютерная рендеринг ванной комнаты показывает каменные стены и большой туб с окном.',\n 'Стакан зубных щеток, сидящий на прилавке',\n 'изображение трех зубных щеток в боковом стеклянном держателе',\n 'Три зубных щетки сидят внутри стакана на прилавке.',\n 'Три цветные зубные щетки, стоящие в стеклянном держателе.',\n 'Три зубных щетки в прозрачной стеклянной чашке.',\n 'Мужчина наклоняется, когда она осматривает женскую обувь.',\n 'это двое мужчин, стоящих на лестнице',\n 'Мужчина стоит перед женщиной рядом с чемоданом.',\n 'человек стоя и человек, смотрящий вниз',\n 'мужчина, стоящий на коленях, глядя на дамские туфли',\n 'крупный план кота, лежащего на траве рядом с обувью',\n 'Кошка в траве жует сапоги.',\n 'изображение кота, играющего ботинком',\n 'Кошка, играющая ботинком на поле.',\n 'Кот лежит в траве рядом с обувью.',\n 'Коричнево-белый чууахуа стоит над фаршированной игрушкой-жирафом и желтой лентой.',\n 'Собака Чуахуа стоит рядом с игрушечным жирафом и смотрит вверх.',\n 'Маленькая собачка смотрит в камеру.',\n 'на полу сидит бежево-бежевая собака',\n 'Чуахуа смотрит вверх на деревянную конструкцию, а не на ров на земле.',\n 'тарелку вкусной еды какого-нибудь',\n 'Еда на белой тарелке с овощами и гарниром.',\n 'На тарелке вареное пахучее блюдо.',\n 'Изображение миски с едой, состоящей в основном из овощей.',\n 'Крупным планом фотография еды на белой тарелке.',\n 'Телевизор, сидящий рядом с рекой с разбитым экраном.',\n 'Телевизор, сидящий посреди реки',\n 'Есть старый телевизор посреди болота',\n 'Старый телевизионный монитор сидит посреди потока.',\n 'Телевизор посреди быстротечной реки.',\n 'Стадо слонов, идущих по полю сухой травы.',\n 'Стадо слонов и их телят гуляет в одной папке',\n 'Стадо слонов пересекает экзотическую саванну.',\n 'Стадо слонов, в шеренге, идущее по саванне.',\n 'Слышал, что слоны идут по полю в шеренге.',\n 'Чашка кофе на тарелке с ложкой.',\n 'Чашка капучино рядом с пластинками десертов.',\n 'Чашка кофе с десертом на деревянном столе.',\n 'Чашка жидкости с причудливым дизайном сверху.',\n 'Выпечка, вода и чашка кофе с ложкой.',\n 'Большая группа нафаршированных животных, сидящих на красной кровати.',\n 'ярко декорированная спальня с разнообразными фаршированными животными в комнате',\n 'Куча забитых животных, лежащих на кровати.',\n 'Группа плюшевых медведей, лежащих на красной кровати.',\n 'На кровати навес с красными простынями, на нем - куча чучела животного, на тумбочке рядом с кроватью - две пушистые лягушки.',\n 'несколько больших плиток, как на трамвайных путях, и несколько оранжевых напольных плиток',\n 'Сковородки из теста сидят на лопатках, держа в руках сковородки.',\n 'пару пацанов, сидящих на тряпках',\n 'Крупные сырники сложить в разогретую духовку.',\n 'Три кастрюли пиццы в картонной коробке, которая держит пиццу.',\n 'Три молодые женщины пытаются поймать фрисби.',\n 'Группа женщин, стоящая в поле и пытающаяся поймать фрисби',\n 'Три девушки играют в фрисби вместе в поле.',\n '3 человека пытаются поймать фризби в середине пути.',\n 'три человека на травяном поле потянулись за фрисби в воздухе',\n 'Ржавый красный мотоцикл припарковался возле красного здания.',\n 'Мотоцикл припарковался на обочине здания с фреской',\n 'Старый мотоцикл припарковался у ржавого здания.',\n 'Старый мотоцикл стоит на его кикстенде у двери, перед стеной с фреской из дерева.',\n 'Крупным планом мотоцикл припарковался на тротуаре рядом с дверью.',\n 'Молодой человек катался на скейтборде по трамплину.',\n 'Человек, стоящий на скейтборде и катающийся в парке.',\n 'Подросток катается на скейтборде в скейт-парке.',\n 'Человек, катающийся на скейтборде на рейве.',\n 'Ребенок на скейт-доске, катающийся на раме.',\n 'На компьютерном мониторе изображена набитая черепаха.',\n 'Компьютер стоит на столе вместе с несколькими ножами.',\n 'Настольный компьютер с фаршированной черепахой на вершине.',\n 'Компьютерный стол с настольным компьютером и фаршированной черепахой сверху.',\n 'Настольный компьютер и монитор на столе.',\n 'кошка сидит на крыше автомобиля',\n 'Кошка, сидящая на крыше автомобиля рядом с ним.',\n 'черно-белая кошка, автомобиль и собака.',\n 'Кэт сидит на крыше автомобиля с кистью сзади.',\n 'Любопытный вид кота, сидящего в машине.',\n 'Мотоцикл припарковался на парковке во многих местах.',\n 'есть оранжево-черный мотоцикл, который припаркован',\n 'Золотой мотоцикл припарковался на парковке рядом со зданием.',\n 'Мотоцикл припарковался на парковке перед магазином.',\n 'Золото-черный мотоцикл припаркован у травы.',\n 'Поезд с угрюмыми глазами, сидящий возле платформы.',\n 'Трейлер с ярко-полосатой задней частью с приставками и наблюдателями на перроне.',\n 'желто-черный раздетый поезд рядом с тротуаром',\n 'На станции припарковался локомотив поезда с тележками.',\n 'есть поезд, который останавливается на станции',\n 'Ящики со свежими фруктами на рынке.',\n 'Экспозиция коробок с несколькими видами фруктов.',\n 'Аппликации, апельсины и другие фрукты выставлены на продажу в коробках',\n 'Куча коробок с разнообразными фруктами на витрине.',\n 'Фруктово-овощной стенд с едой, выставленной в продуктовых коробках.',\n 'Статуя человека на вершине лошади.',\n 'Статуя человека на лошади и группа деревьев без листьев за ней.',\n 'Статуя человека с мысом на коне перед деревьями и зданием.',\n 'Статуя солдата, сидящего на лошади',\n 'Статуя римского солдата, сидящего на коне.',\n 'Песчаный пляж, покрытый белыми досками для серфинга рядом с океаном.',\n 'доски для серфинга, сидящие на пляжном песке',\n 'Большой пустой пляж с кучей досок для серфинга.',\n 'Элевенские доски для серфинга лицом вниз на пустом пляже.',\n 'Многие доски для серфинга лежат в песке на пляже.',\n 'Белый и красный автобус на обочине улицы.',\n 'Большой длинный белый автобус на дороге.',\n 'Красно-белый автобус ехал по обочине дороги.',\n 'Пассажирский автобус припарковался на улице с закатом на заднем плане',\n 'Автобус припаркован на тихой дороге в ожидании своих пассажиров.',\n 'Женщина с кошкой в зеркале.',\n 'женщина, делающая селфи перед стопкой зеркал',\n 'Женщина делает снимок, глядя в зеркало, в то время как кошка наблюдает.',\n 'Зеркало из трех частей с девушкой, фотографирующей его в кадре',\n 'Женщина и кошка, отраженные в зеркале, состоящем из трех частей',\n 'Человек едет на мотоцикле по проселочной дороге.',\n 'Мужчина на мотоцикле идет по улице.',\n 'Автомобилист едет по загородному двухполосному шоссе.',\n 'человек, ехавший на мотоцикле по дороге с деревьями',\n 'Мужчина на мотоцикле рядом с пышным зеленым лесом.',\n 'Жираф стоит один в очень высокой кисти.',\n 'жираф, стоящий перед деревом',\n 'Один жираф стоит среди нескольких оживленных деревьев.',\n 'Жираф, стоящий в стойле деревьев.',\n 'Жираф, стоящий один рядом с деревом.',\n 'Набор из двух фотографий двух мужчин в ванной комнате.',\n 'Ванная комната переделана, покрашена и украшена',\n 'Две ванные комнаты с разным декором на каждой из них',\n 'Две разные ванные комнаты, одна с зеленым туалетом',\n 'раздробленная фотография с некоторыми внутренними деталями',\n 'темная комната с тремя людьми на компьютерах',\n 'Люди сидят в темноте, пользуясь компьютерами.',\n 'Люди используют свои компьютеры в темноте.',\n 'Дополнительный ноутбук находится в режиме ожидания для пользователей компьютера.',\n 'Группа людей, которые сидят перед ноутбуками.',\n 'Люди собираются возле ярко-оранжевых воздушных шаров.',\n 'группа людей в поле, летающая большими поплавками',\n 'Днем на поле летят разноцветные киты.',\n 'Одежда всегда под рукой, чтобы помочь людям с котятами.',\n 'Клоуны кивают друг другу на авиашоу.',\n 'Мотоцикл припаркован у кафе.',\n 'Мотоцикл припаркован перед кафе.',\n 'Бар и кафе с мотоциклом припарковались спереди.',\n 'У бара стоит большой мотоцикл.',\n 'мотоцикл припарковался перед небольшим кафе',\n 'Женщина в розовой шляпе с черной пуговицей.',\n 'Дама стоит в залитом водой месте в окружении палаток.',\n 'Женщина под водой, стоящая в воде на затопленном поле с тентами на заднем плане.',\n 'В довольно большой луже стоит женщина, держащая в руках пуговицу.',\n 'Самка кампера, стоящая по щиколотку глубоко в воде под пуповиной',\n 'Женщина разрезает большой торт с зажженной свечой.',\n 'Женщина с ножом, разрезающим торт.',\n 'женщина, разрезающая большой именинный торт при одной свече',\n 'Женщина, разрезающая большой торт одной зажженной свечой.',\n 'Женщину фотографируют, когда она режет торт.',\n 'Жираф поворачивает голову, чтобы посмотреть на фотографа',\n 'Жираф, стоящий и позирующий в окружении ирисов.',\n 'жираф, стоящий в высокой траве с деревьями на заднем плане',\n 'Жираф стоит в одиночестве в дикости.',\n 'Жираф в поле, голодающий перед камерой.',\n 'Туалет с раковиной, тизерами и зеркалом',\n 'В ванной комнате есть бутылка чистящих салфеток.',\n 'Небольшая ванная комната со стеклянной душевой дверью, раковиной, туалетом и дезинфицирующими салфетками.',\n 'Желтый дозатор для протирки Clorox, сидящий на раковине ванной комнаты.',\n 'Небольшая ванная комната с зеркалом, душем, туалетом и тщеславием.',\n 'Гостиная с мебелью на полу из твердого дерева.',\n 'гостиная с большими диванами и потолочным вентилятором',\n 'гостиная, заполненная диванами и кулером, сидящим на твердом деревянном полу',\n 'Гостиная с деревянными диванами и стулом.',\n 'Очень большая красиво выглядящая комната с ярким окном.',\n 'Кайт-серфер поднимает воду во время серфинга.',\n 'Мужчина катается на водных лыжах на вершине водоема.',\n 'В то время как фиолетово-голубое небо с чем-то похожим на воздушный змей или рыхлый парасаил, плавающий в нем, покрывает большую часть расстояния выстрела, на нижней части изображены боковые берега и водоем с вытягивающимся водометом.',\n 'Человек, который занимается виндсерфингом в воде.',\n 'Пароход откидывается назад и тянется на подсоединенный к нему пиловочник.',\n 'семья садится за стол, чтобы поесть торта',\n 'Группа за столом в ожидании именинного торта.',\n 'взрослые за столом столовой с именинным тортом.',\n 'Четыре человека, сидящие за обеденным столом для пирожных и напитков.',\n 'Группа людей собирается вокруг стола с тортом на нем.',\n 'Многие идут с чемоданами по вокзалу.',\n 'Прохожие идут вдоль желтого поезда внутри станции',\n 'СОБЫТИЕ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕОПЛЯ ОТ ПЕ',\n 'Желтый поезд влетел в железнодорожную платформу, заполненную людьми',\n 'Поезд, проходящий через станцию по среднему пути.',\n 'Два слона лицом друг к другу, и один трогает другого своим хоботком',\n 'Два слона, играющие или агрессивные с копытами.',\n 'Два очень больших слона, играющих вместе на поле.',\n 'Два слона играют друг с другом на поле.',\n 'Пару слонов, играющих друг с другом.',\n 'Очень большая часовая башня на стороне церкви.',\n 'Старое здание с часами наверху.',\n 'Высокая часовая башня встроена в угловой край здания.',\n 'В старом здании есть часовая башня с погодой.',\n 'Показана часовая башня старого здания.',\n 'Три утки рядом с берегом пруда',\n 'На вершине озера плавает стая уток.',\n 'Три утки у воды снаружи.',\n 'Три гуся, которые стоят у пруда.',\n 'Три утки, идущие вдоль дока у воды.',\n 'Черно-белая фотография двух мужчин на обочине дороги.',\n 'Два человека у церкви и автостоянки.',\n 'старое черно-белое фото двух человек',\n 'Двое мужчин, стоявших рядом у припаркованных автомобилей',\n 'Двое мужчин снаружи возле машины и двигают какой-то карабин.',\n 'Cat Siamese looking sleeping on its side on a comforter.',\n 'белая кошка, лежащая на кровати и спящая',\n 'Черно-белая фотография кота, сидящего на кровати',\n 'Кошка, спящая на кровати рядом с утешителем.',\n 'Белая кошка, спящая на кровати на солнце',\n 'Мужчина на доске для серфинга в воде.',\n 'Мужчина стоит на доске для серфинга и держит палку.',\n 'Человек в кепке на доске для серфинга и держащий весло.',\n 'Парень в кепке серфингует на волне',\n 'Человек с падалью, катающийся на волне на доске для серфинга.',\n 'this is two men in cleats on the grass',\n 'Два молодых человека играют в фрисби в парке.',\n 'Пару мужчин, играющих в фрисби друг против друга на поле.',\n 'Два подростка играют в игру Фрисби на поле.',\n 'Двое молодых людей играют с фрисби в сквере.',\n 'изображение сэндвича из куриного салата',\n 'Два куска хлеба с соусом на них рядом с миской куриного салата.',\n 'Бутерброд покрывается соусом и салатом.',\n 'Бутерброд, покрытый красным саком и куриным салатом.',\n 'Чаша с салатом туна рядом с двумя ломтиками хлеба, увенчанными салатом, и один с кетчупом на нем.',\n 'Мужчина на лодке, держащий собаку на коленях.',\n 'Мужчина катается на лодке по океану, держа в руках благородную собаку быка.',\n 'Собака и ее хозяин на спине лодки.',\n 'Мужчина, держащий свою собаку в лодке.',\n 'Мужчина, держащий щенка на лодке.',\n 'Молодой человек лежит на земле в лыжах.',\n 'человек на земле в лыжах',\n 'Скайер в синей куртке лежит в снегу на животе.',\n 'Упавший в снег скейтер',\n 'Человек, лежащий на земле на лыжах.',\n 'Ночью улица с гуляющими людьми и подсвеченными зданиями.',\n 'Городская улица с множеством высоких освещенных зданий.',\n 'Ночью в чужой стране загорелась оживленная городская улица.',\n 'Ночью улица в центре города с неоновыми вывесками.',\n 'Городская улица освещена вывесками и зданиями.',\n 'На столе сидит миска с бананами и другими блюдами.',\n 'Фрукты в керамической миске на деревянном столе с белыми стенами',\n 'На столе стоит миска с фруктами.',\n 'В миске на столе - чаша экзотических фруктов.',\n 'Чаша с фруктами на столе.',\n 'Каркас крепится к стене рядом с кухней.',\n 'Внутренний декор в средней кухне.',\n 'Домашняя кухня с постерами из Нэшвилла, Теннесси',\n 'Кухня с табличками на стене снаружи.',\n 'Кухня с искусством и меню висит на стене',\n 'Компьютер стоит на столе рядом с бардаком.',\n 'Рабочий стол с монитором компьютера и клавиатурой.',\n 'Компьютер, сидящий на столе со свечами и напитками у него.',\n 'Хакеры, Starburst и бутылка воды лежат на столе рядом с компьютером.',\n 'Компьютер с пустой бутылкой, чашкой и коробкой кракеров рядом.',\n 'Во время авиашоу появляется реактивный самолет.',\n 'Реактивный самолет на тармаке с людьми и облачным небом',\n 'Самолет, сидящий на взлетно-посадочной полосе.',\n 'Несколько самолетов, сидящих на тармаке в аэропорту.',\n 'Два самолета садятся на тармак в солнечный день.',\n 'мужчина с шеи вниз в костюме и галстуке',\n 'есть человек, сидящий в поезде в костюме',\n 'Мужчина, держащий руки рядом со своими мячами и носящий часы.',\n 'Мужчина в костюме и галстуке сидит с руками между ног.',\n 'Есть человек с руками на коленях',\n 'Маленький малыш, который катается на скейтборде.',\n 'Черно-белая фотография счастливой девушки катающейся на скейтборде',\n 'Черно-белая фотография маленькой девочки на скейт-доске.',\n 'Молодая девушка в шлеме катается на скейтборде.',\n 'Молодая девушка катается на скейтборде через школьный двор.',\n 'Два очень больших слона стоят вместе в вольере.',\n 'два слона, стоящие рядом друг с другом на котловане рядом с деревьями.',\n 'Два слона в зоопарке сидят на листьях.',\n 'Люди стоят рядом, наблюдая за тем, как пара слонов весело гуляет вместе',\n 'два слона на дайверской площадке рядом с трес',\n 'Открытая книга рядом с ноутбуком на кровати',\n 'Книга, открытая и лежащая на столе.',\n 'Открытая книга рядом с компьютером и одеждой.',\n 'крупным планом книгу рядом с ноутбуком на кровати',\n 'Кровать с книгой, черный ноутбук и одеяло.',\n 'люди построили собачий домик в форме замка из песка',\n 'Красный огненный гидрант и песчаная скульптура на пляже.',\n 'Собака и кошка сделаны из песка игрушечным пожарным гидрантом.',\n 'Кто-то на пляже построил песчаный домик.',\n 'Догхантер и собаки лепили из песка игрушечного пожарного гидранта.',\n 'Витрина люкса за стеклом с плакатом \"Австралия на заднем плане\".',\n 'Экспозиция, заполненная плакатами и транспарантами.',\n 'пара корыт в стеклянном ящике',\n 'Настройка дисплея с кучей багажника на рубашке.',\n 'Экспозиция австралийских трюмов в различных размерах',\n 'девушка в галстуке и платье',\n 'женщина в галстуке, держащаяся за почти пустое пиво',\n 'Женщина с пивом в галстуке.',\n 'есть женщина, держащая в руках пиво и танцующая',\n 'эта женщина пьет пиво и танцует',\n 'сноубордист в синих штанах, стоящий на сноуборде',\n 'Сноубордист, отдыхающий, сидя в снегу.',\n 'Ноги человека на сноуборде в снегу.',\n 'Сноубордист ложится, чтобы показать свои ноги и ноги на сноуборде.',\n 'Ноги человека в снегу в сноуборде.',\n 'Пара кошек, лежащих на диване в комнате.',\n 'На диване лежат три кошки.',\n 'Три кошки растянуты на диване.',\n 'пару кошачьих котов, высунувшихся на диване',\n 'Кот, лежащий на диване с подушками',\n 'Торт анимационного персонажа с бантом на голове.',\n 'Торт, украшенный, чтобы выглядеть как самка мыши.',\n 'Лицо собаки с торчащим языком.',\n 'Торт Минни-Мышка сидит на разделочной доске.',\n 'крупный план торта, сделанного, чтобы выглядеть как мышь Минни',\n 'Человек, размахивающий пачкой бананов в коробке.',\n 'Человек, отбирающий бананы из букета.',\n 'Человек, вытаскивающий кусок банана в мусорный бак.',\n 'Парой рук на коробке из-под апельсинов расщепили кусочек бананов.',\n 'Человек держит в руках маленькую порцию бананов.',\n 'Пару жирафов в районе.',\n 'Некоторые жирафы тусуются вместе в закрытой зоне.',\n 'Два жирафа стоят в закрытой зоне.',\n 'Два жирафа стоят рядом друг с другом в зоопарке.',\n 'Два жирафа, один взрослый, один молодой, гуляют по заснеженной местности, пока другой лежит на земле.',\n 'МАН НА ЧЕЛОВЕЧНОМ ФОНЕ, ИМЕЮЩЕГОСЯ НА УСТРОЙСТВЕ КОРНЕРА В ДОМОВЫХ СЛИППЕРСАХ',\n 'Мужчина в кожаной куртке, шортах и кроссовках.',\n 'Мужчина в тапочках, стоящий на обочине улицы и разговаривающий по мобильному телефону.',\n 'человек, стоящий на городской улице в шортах и тапочках',\n 'Мужчина, стоящий на тротуаре в нижнем белье в тапочках для животных.',\n 'группа людей шла рядом со зданием со своими чемоданами',\n 'Вид сверху на нескольких людей, идущих по улице с багажником.',\n 'Мужчины и женщины, идущие по улице и тротуару со своим багажником.',\n 'Улица с людьми, несущими свои сумки и чемоданы',\n 'Люди идут по тротуару со своим багажником.',\n 'Двое мужчин позируют во время фотографирования.',\n 'Трое теннисистов-мужчин в лесополосе.',\n 'двое мужчин, стоящих рядом друг с другом, чтобы сфотографироваться',\n 'Человек с рукой вокруг другого человека.',\n 'Два человека, позирующих для фотографии в большом количестве.',\n 'Собака, сидящая в сердце на пляже у океана',\n 'Коричневая собака на пляже в окружении формы сердца.',\n 'На песке изображена фигура в форме сердца, в центре которой сидит собака.',\n 'собака сидит на пляже внутри нарисованного сердца',\n 'Симпатичная маленькая собачка, сидящая в сердце, нарисованном на песчаном пляже.',\n 'Нож и вилка лежат на тарелке с овощами и мясом.',\n 'тарелка, в которой есть разные виды продуктов',\n 'Чей-то ужин состоял из брусселя и мяса.',\n 'Тарелка еды с картофелем, овощами и мясом.',\n 'Тарелка с тушенкой, картофелем и овощами.',\n 'некоторые велосипедисты переходят улицу',\n 'Люди в шлемах во время езды на велосипедах, пересекающих улицу.',\n 'Велосипедисты переходят улицу перед автомобилем.',\n 'Группа велосипедистов, переходящих мощеную улицу.',\n 'Несколько велосипедистов переходили улицу по обозначенному пешеходному переходу на проезжей части.',\n 'Пицца из сладкого перца, сидящая на сковороде.',\n 'Пицца из пепперони на тарелке, сидящая на столе.',\n 'Маленькая пицца, на которой, кажется, есть перец.',\n 'Пепперони пицца с дополнительным сыром и бледным густым тестом.',\n 'Пицца с перцем, сидящим на тарелке на столе.',\n 'большой самолет, летящий по небу с горами на заднем плане',\n 'Самолет высоко летит над лесом с горами вдали.',\n 'Пассажирский самолет с вытянутым шасси летит в небе над зеленой лесистой местностью и горами вдалеке.',\n 'Самолет находится близко к земле рядом с горой и деревьями.',\n 'Большой пассажирский самолет готовится к посадке перед группой гор.',\n 'Инструменты, расположенные на столе: ножницы, фрезы проволоки, нож и шестигаечный ключ.',\n 'Небольшая группа инструментов выложена на столе.',\n 'Пара ножниц, ножницы и гаечный ключ на столе.',\n 'Ножницы, ножницы и коробочный нож лежат на столе.',\n 'Куча различных инструментов, сидящих на столе.',\n 'Оранжевый кот, лежащий на кровати с черным утешителем.',\n 'коричневый кот, спящий на кровати с синим одеялом',\n 'Кот лежит на кровати с синими простынями.',\n 'Кошка, спящая на кровати с подушкой',\n 'Коричневая кошка свернула, спящая на человеческой кровати.',\n 'Железнодорожная станция рядом с заснеженным горным поясом.',\n 'красивый поезд, движущийся рядом с жилыми домами и горами',\n 'Поезд, следовавший вдоль здания, накрыл крышу.',\n 'поезд со зданиями с горой на заднем плане',\n 'Поезд, проезжающий через город у большой горы.',\n 'Женщина, стоящая на коленях, чтобы погладить лежащую на земле черно-белую корову.',\n 'женщина, стоящая на коленях рядом с коровой, лежащей на земле',\n 'человек, стоящий на коленях перед маленькой коровой',\n 'Женщина петит корову в петушином зоопарке.',\n 'Молодая женщина, которая кормит корову, лежит.',\n 'В ванной комнате есть туалет, раковина и зеркало.',\n 'Фотография ванной комнаты в доме.',\n 'Свет ярко сияет из окна в маленькой ванной комнате.',\n 'Есть отсутствующая дверь в ванную комнату.',\n 'The bathroom is white and has brown tiles on the floor',\n 'Человек, стоящий на снегу рядом с деревом.',\n 'Человек со сноубордом стоит в заснеженном поле.',\n 'Человек медленно пробирается по снегу,',\n 'Молодой человек с горкой посреди заснеженного двора.',\n 'Лыжник на снегу с лыжами.',\n 'Многие пропеллеры и бипланы выставлены в музее.',\n 'Винтажный винтовой самолет, висящий на дисплее.',\n 'Небольшой самолет висит в подвешенном состоянии',\n 'В воздухе висит военный самолет.',\n 'Самолет подвешен к потолку в музее.',\n 'Мужчина, выполняющий трюк на скейтборде.',\n 'Мужчина пытается прыгнуть на скейтборде.',\n 'Конькобежец сосредоточен на своем последнем трюке.',\n 'Человек в рубашке делает трюк на скейтборде.',\n 'Мужчина прыгает в воздух на скейтборде.',\n 'Большое поле, рядом лес деревьев.',\n 'В небе над травяным полем пронесся грохот.',\n 'Посадка с грязью и деревьями под струей самолета.',\n 'План над чистым полем рядом с лесом',\n 'коричневый пейзаж с полем и зелеными деревьями',\n 'Грузовой поезд, идущий по железнодорожным путям.',\n 'красный и желтый локомотив поезда тащил свои вагоны и несколько путей',\n 'Поезд, идущий по железнодорожным путям рядом с лесом.',\n 'Очень большой красиво выглядящий поезд на путях.',\n 'локомотивный поезд на железнодорожном полотне с прицепленными за ним вагонами-цистернами.',\n 'Черно-белая кошка, лежащая поверх разноцветной кошки.',\n 'Кошка, сидящая внутри пумбера на диване.',\n 'Кошка сидит в амбразуре, которая сидит на диване.',\n 'кот, сидящий внутри черной сумки.',\n 'Кошка сидит в открытой, опрокинутой пуме.',\n 'Бутерброд и бокал вина в закусочной на улице.',\n 'Открытый обеденный дворик с бутербродом и бокалом вина.',\n 'бутерброд на тарелке рядом с бокалом вина на столе',\n 'Крупным планом бутерброд, состоящий из рулета и копченого лосося',\n 'На столе в ресторане, расположенном на углу улиц, стоит бокал вина и рыбный бургер.',\n 'Женщина, стоящая на кухне рядом с банками на прилавке.',\n 'Женщина с фруктами и овощами на кухонном прилавке с кастрюлей с соусом на плите.',\n 'Женщина кладет еду в банки, чтобы держать их свежими',\n 'Женщина готовит стеклянные банки, наполненные жидкостью, на своем прилавке.',\n 'Женщина, стоящая у своего кухонного прилавка за овощами.',\n 'Гостиная, заполненная мебелью и картинами на стенах.',\n 'Гостиная с видом на столовую',\n 'В гостиной есть стулья, лежаки и книжный шкаф.',\n 'Сцена в гостиной с открытой дверью, ведущей в столовую.',\n 'Приют с кошачьей чешуей стойкой, стульями и лапшой.',\n 'Оранжевая лодка опрокинулась рядом с платформой.',\n 'Несколько лодок припарковались в большом водоеме.',\n 'Море с множеством лодок, стоящих на якоре в бухте',\n 'Пристань на озере или в океане',\n 'Несколько старых лодок на воде, сидящих в доке.',\n 'Модель красного самолета висела на потолке.',\n 'Красный самолет свисает с потолка.',\n 'С потолка свисает красный самолет.',\n 'Красно-белый самолет, свисающий с потолка.',\n 'Самолет, который висит в воздухе.',\n 'Парень, играющий с фрисби на улице в дневное время.',\n 'Человек стоит, как фризби летит в воздухе.',\n 'Мужчина в парке только что бросил фрисби.',\n 'Мужчина бросает фрисби в зеленое поле.',\n 'Человек, бросающий красную фрисби в парке.',\n 'Люди стоят в песке на пляже, летят воздушные змеи.',\n 'Три человека на пляже, один летит воздушным змеем.',\n 'Три человека на пляже запустили над собой воздушный змей',\n 'Люди с зонтиком на гладком пляже.',\n 'Три человека на пляже летают на большом воздушном змее.',\n 'Мужчина в футболке и шлеме агрессивно позирует с бейсбольной битой в руке.',\n 'мужчина, одетый в кокетливый костюм',\n 'Мужчина, одетый в костюм домохозяйки, носит бейсбольную биту и гримасы.',\n 'Мужчина в смешном костюме позирует для картины.',\n 'Мужчина, держащий бейсбольную биту, стоя в аэропорту.',\n 'Ванная комната с туалетом, раковиной, окном с занавеской, окрашенными деревянными стенами и полом наполовину из дерева и наполовину из бетона.',\n 'Ванная комната с туалетом, раковиной и окном в ней.',\n 'Очень маленький, избитый санузел в старом здании.',\n 'В этом туалете есть туалет, окно и раковина.',\n 'Ванная комната старого вида, только туалет и раковина.',\n 'Человек с амбразурой, идущий рядом с цветами.',\n 'Человек идет под дождем рядом с цветами.',\n 'Женщина, идущая по тротуару с амбразурой.',\n 'Мост в городском парке, вокруг которого растут цветы.',\n 'Человек, идущий по дорожке с оранжевой буквой.',\n 'Два жирафа наслаждаются совместной трапезой.',\n 'Пару жирафов, стоящих рядом с высоким зданием.',\n 'Два жирафа едят сено из поднятой кормушки.',\n 'Жирафы приходят на сенокос, чтобы быстро перекусить.',\n 'два жирафа едят корм из мусорного бака',\n 'Самолет, летящий в воздухе над мотоциклом.',\n 'Между самолетом и мотоциклом происходит обмен пассажирами по трапу.',\n 'Человек на лестнице, висящий с самолета над мотоциклом.',\n 'Мужчина, висящий на лестнице, прикрепленной к летящему небольшому самолету, с человеком на мотоцикле под ним.',\n 'Каскадер на лестнице подвешен к движущемуся самолету с двигающимся внизу мотоциклом.',\n 'Пожилая женщина в инвалидной коляске открывает рождественские подарки',\n 'Пожилая женщина, сидящая в инвалидной коляске с большим белым плюшевым медведем.',\n 'Женщина в инвалидной коляске, держащаяся за плюшевого мишку.',\n 'Человек, который держит плюшевого медведя, сидя.',\n 'Пожилая женщина в инвалидной коляске позирует с большим набитым медведем.',\n 'Стадо слонов, гуляющих по полю',\n 'ЭТО ПИКТУРА ОТ КРУПНОЙ СЕМЬИ ОТ ЭЛЛИХАНТОВ',\n 'группа слонов, стоящих вокруг и поедающих траву',\n 'Стадо слонов с большими и малыми слонами в зоопарке.',\n 'Молодой слон зажался между группой взрослых слонов',\n 'Блюда, которые включают в себя различные виды десертов.',\n 'Две тарелки и миска с едой, сидящая на столе.',\n 'Есть миска с хлебом и тарелка с фруктами.',\n 'Завтрак из каши, фруктов и быстрого хлеба.',\n 'Стол с запеченным хлебом, слайсами и зажаренным салатом.',\n 'Многие косметические предметы расположены рядом с картой.',\n 'Ассортимент передвижных экспонатов, выставленных на деревянном столе.',\n 'Представлены несколько предметов, которые обычно можно найти в женском кошельке.',\n 'Стол, увенчанный личными вещами и вещами.',\n 'Несколько предметов на столе для похода или кемпинга',\n 'Группа мужчин стоит у прилавка на кухне.',\n 'Группа мужчин на кухне делает зарядку.',\n 'Пятеро мужчин на кухне, двое сидят на прилавке, а один с пивом в руке.',\n 'группа людей, пытающаяся заручиться поддержкой',\n 'Пять человек в доме, один держит бутылку',\n 'Жираф, пытающийся съесть листья на верхушке ветки',\n 'Жираф, пожирающий ветку дерева на открытом поле.',\n 'жираф, грызущий ветку дерева',\n 'Жираф стоит и вставляет в рот ветку дерева.',\n 'старается есть листья, которые уже съели',\n 'Большое здание с часами и людьми рядом.',\n 'Большая часовая башня над маленьким городом.',\n 'Большая широкая улица рядом с высокой башней с часами.',\n 'Европейская городская площадь с часовой башней.',\n 'Изображение старой часовой башни в центре города.',\n 'человек сидит на траве, ест еду и пьет',\n 'Хорошо снять обувь и расслабиться на солнце на обед.',\n 'Мужчина режет еду парой синих ножниц.',\n 'Человек, сидящий спиной к дереву.',\n 'Мужчина наслаждается закуской в парке.',\n 'Вид из гостиной в столовую дома',\n 'Кухня показана с телевизором, установленным на стене.',\n 'стол со стульями, прилавок с табуретками с большими окнами',\n 'Вид на столовую и барную зону в доме.',\n 'Гостиная с настенным телевизором рядом со столом.',\n 'Человек, держащий в руках трау, полную оранжевой морковки.',\n 'Человек, держащий рядом с транспортным средством вагон с морковкой.',\n 'Женщина везет морковь на грузовике',\n 'Женщина везет по улице пачку морковки.',\n 'Женщина в разноцветном платье, несущая по бездорожью морковку.',\n 'Мужчина в купальных шортах катается на доске для серфинга.',\n 'Серфер катается на волне в океане.',\n 'Подтянутый молодой человек, катающийся на волне в океане.',\n 'Мужчина катается на доске для серфинга на волне.',\n 'Безропотный человек, катающийся на короткой воде на волне.',\n 'Коммерческий самолет с открытой дверью и заходящими людьми.',\n 'Большой реактивный самолет, сидящий на крыше взлетно-посадочной полосы аэропорта.',\n 'ЗДЕСЬ ПЛАТ КОННЕКЦИОННОЙ ПЛАТЫ ДЕЛЬТЫ, КОТОРЫЙ УСТАНОВЛЯЕТСЯ НА ЯРДЕ',\n 'Пассажирский самолет, соединяющий дельту, готов к посадке.',\n 'есть люди, садящиеся в очень большой самолет',\n 'Красивая молодая женщина едет на заднем сиденье мотоцикла.',\n 'Женщина на мотороллере, проезжающая по узкой улочке.',\n 'женщина в белом шлеме, припаркованная у бордюра',\n 'Кто-то делает что-то довольно забавное.',\n 'Женщина, сидящая на маме на улице',\n 'Большая кошка и маленькая кошка садятся спиной',\n 'Две кошки сидят рядом, глядя в телевизор.',\n 'пару кошек, которые находятся перед домом.',\n 'Пара кошек, сидящих на столе и вместе смотрящих телевизор.',\n 'Кошка и котенок вместе смотрят телевизор.',\n 'Оранжевый кот, стоящий на вершине коричневой лошади.',\n 'Оранжевый кот, стоящий на спине темной лошадки.',\n 'кот стоит на вершине лошади',\n 'Кошка, стоящая на вершине черного коня.',\n 'Кошка гордо и полно доблести верхом на лошади',\n 'молодой парень, идущий в форресте, держа в руке предмет',\n 'Частично черно-белая фотография человека, бросающего что-то в мусор.',\n 'Дисковый гольфист совершает бросок из ящика для прыжков в воду по покрытому лесом полю.',\n 'Человек находится на расчистке лесистой местности.',\n 'человек, бросающий фрисби во многие деревья',\n 'Человек верхом на лошади.',\n 'Человек, сидящий на лошади на холме',\n 'Человек, сидящий на лошади на вершине холма.',\n 'индиец верхом на черно-белом конном сарае.',\n 'Человек на коне без грусти стоит на холме.',\n 'Люди стоят вокруг старого самолета, который наклонен к его носу.',\n 'Большой самолет, летящий над полем, покрытым травой.',\n 'В поле разбился самолет.',\n 'Старая фотография самолета на земле',\n 'Или большой самолет врезался в поле на траве.',\n 'Кухня с центральной островной печью и холодильником из нержавеющей стали.',\n 'Кухня с центральным островом и метафорическим холодильником.',\n 'Ухоженная и чистая кухня с горелками для счетчиков',\n 'Хорошо освещенная кухня с островом и холодильником из нержавеющей стали',\n 'изображение кухонного гарнитура с безстебельной сталью.',\n 'Человек, летающий на воздушном змее в облачном голубом небе.',\n 'Мужчина, поднимающий в воздух воздушный змей.',\n 'Мужчина, летающий на воздушном змее в горах.',\n 'Мужчина держится за мощный воздушный змей.',\n 'Человек запускает воздушный змей в голубое небо.',\n 'Ребенок в шляпе Санта-Клауса и сапогах держит в руках пару игрушек.',\n 'Маленький мальчик, который стоит у прилавка.',\n 'ребенок на кухне на ступенчатой лестнице',\n 'Мальчик в пеленке и шляпе Санта-Клауса на кухне.',\n 'мальчик в шляпе санта, держащий на кухне пару орешков',\n 'Широкий панорамный снимок Лондона в дневное время.',\n 'здание с большой часовой башней на нем',\n 'Большое здание с часовой башней.',\n 'большое здание, в котором есть несколько игрушек с часами наверху',\n 'Здание в городе было очень большим.',\n 'Женщина посреди качающейся теннисной дорожки.',\n 'Теннисистка раскачивает ракетку на корте.',\n 'Человек, ударяющий мячом по теннисному корту.',\n 'Теннисистка в розовой рубашке раздвигает свои раны.',\n 'женщина с теннисным мячом в руке',\n 'Человек на четырехколесной пастушьей овчарке в снегу.',\n 'Человек управляет стадом овец на четырехколесном транспортном средстве.',\n 'Мужчина на четырехколесном мотоцикле гоняет стадо овец.',\n 'Водитель может легко пасти овец на квадроцикле.',\n 'Большое стадо животных, идущих перед человеком на транспортном средстве.',\n 'Черный трай, держащий корзину с фризами и бутербродом.',\n 'Суб-сэндвич с бокалом фри и безалкогольным напитком.',\n 'У трая есть бутерброд, французский фриз и напиток на нем.',\n 'Трай еды, включая бутерброд, фрис и напиток',\n 'Питание, состоящее из суб, фрис и пепси на трэе.',\n 'Двое взрослых и ребенок на лыжах в снегу.',\n 'Маленький малыш учится кататься на лыжах по снегу',\n 'Два человека на лыжах держат палки в снегу.',\n 'кто-то, кто катается на лыжах по белому снегу',\n 'Маленький ребенок и двое взрослых катаются на лыжах.',\n 'На кухне стоит серебряный холодильник.',\n 'Большой метафорический современный холодильник, сидящий на кухне.',\n 'Рефрижераторная установка серебряного цвета на кухне.',\n 'Высокий, тощий холодильник в углу кухни.',\n 'Серебряный шкаф не соответствует остальной комнате.',\n 'Мужчина катается на доске для серфинга в океане.',\n 'Молодой человек катается на доске для серфинга на небольшой волне.',\n 'человек, катающийся на доске для серфинга на волне',\n 'человек, катающийся на разноцветной доске для серфинга в воде',\n 'Мужчина занимается серфингом со своей доской для серфинга с желтой и черной полосами',\n 'Серебряный прозрачный контейнер для напитков, рядом с которым черная тарелка с фруктами.',\n 'Два плода сидят в миске рядом с блендером.',\n 'Старомодный тип блендера перед старой вывеской.',\n 'Небольшой блендер с миской фруктов рядом',\n 'Блендер, сидящий поверх деревянного пола.',\n 'Мужчина сидит в лодке на реке и пьет бутылку воды.',\n 'Человек в синей шляпе на маленькой лодке.',\n 'Человек, сидящий в лодке в шляпе.',\n 'Мужчина с бутылкой катается на лодке по озеру.',\n 'Мужчина, сидящий на вершине лодки на вершине озера.',\n 'Человек на корте с теннисным мячом.',\n 'Человек, который держит ракетку, стоящую на траве.',\n 'Теннисист бьет по мячу во время матча.',\n 'Теннисист отрабатывает подачу мяча.',\n 'Человек в белом, играющий в теннис на корте.',\n 'Большой коммерческий самолет припарковался на взлетно-посадочной полосе',\n 'Реактивный самолет китайских авиалиний, сидящий на вершине тармака аэропорта.',\n 'Два больших реактивных самолета находятся на взлетно-посадочной полосе аэропорта.',\n 'На аэродроме Тармак замечены два самолета',\n 'Большой самолет в неподвижном положении под открытым небом.',\n 'Несколько человек за столом готовятся нарезать торт.',\n 'девчонки, сидящие за столом с именинным тортом посередине',\n 'Группа детей и пара взрослых за столом с трехслойным именинным тортом.',\n 'Группа девушек, ожидающих, когда им подадут торт.',\n 'Фотография какой-нибудь семьи, празднующей день рождения.',\n 'Молодой человек катался на скейтборде по обочине трамплина.',\n 'Молодой человек катается на скейтборде на рампе.',\n 'Ребенок на скейт-доске в верхней части рампы.',\n 'Мальчик на скейтборде в скейт-парке',\n 'скейтбордист, выполняющий трюки в скейтпарке',\n 'Стадо коров стоит на покрытом травой поле.',\n 'Группа коров в поле с мужчиной на заднем плане.',\n 'несколько коров в поле с человеком за спиной',\n 'Слышно, как коровы стоят перед мужчиной с трамваем.',\n 'На траве пасется стадо тощих коров.',\n 'Пара лодок на реке',\n 'Две прогулочные лодки припарковались на берегу маленькой реки с людьми в каждой из лодок.',\n 'ГРУППА ОТ ПЕОПЛЯ НА ВСЕХ рыбацких катерах, ПУТЕШАЮЩИХ В ПОЛЯРНОМ ПОГОРОДЕ ИХ',\n 'Лодка с женщинами отталкивается от берега.',\n 'Несколько человек находятся на небольших лодках в канале.',\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"del all_data","metadata":{"execution":{"iopub.status.busy":"2023-12-11T21:16:36.868484Z","iopub.execute_input":"2023-12-11T21:16:36.869380Z","iopub.status.idle":"2023-12-11T21:16:36.873466Z","shell.execute_reply.started":"2023-12-11T21:16:36.869346Z","shell.execute_reply":"2023-12-11T21:16:36.872427Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ClipCocoDataset(Dataset):\n    def __init__(\n        self,\n        data_path: str,\n        prefix_length=30,\n        model_type = False,\n        normalize_prefix=False,\n        train=True,\n    ):\n\n     #   self.tokenizer = GPT2Tokenizer.from_pretrained(model_type)\n        self.prefix_length = prefix_length\n        self.normalize_prefix = normalize_prefix\n        if train:\n            with open(data_path, 'rb') as f:\n                all_data = pickle.load(f)\n            print(\"Data size is %0d\" % len(all_data[\"clip_embedding\"]))\n        else:\n            with open(data_path, 'rb') as f:\n                all_data = pickle.load(f)\n            print(\"Data size is %0d\" % len(all_data[\"clip_embedding\"]))\n\n            \n        print(all_data)\n        sys.stdout.flush()\n        self.prefixes = all_data[\"clip_embedding\"]\n        captions_raw = all_data[\"captions\"]\n        \n        self.captions = captions_raw\n\n        self.captions_tokens = []\n        self.caption2embedding = []\n        max_seq_len = 0\n        i = 0\n        for caption in tqdm(captions_raw):\n            self.captions_tokens.append(\n                torch.tensor(self.tokenizer.encode(caption), dtype=torch.int64)\n            )\n            self.caption2embedding.append(self.prefixes[i])\n            i += 1\n            max_seq_len = max(max_seq_len, self.captions_tokens[-1].shape[0])\n\n        all_len = torch.tensor([len(self.captions_tokens[i]) for i in range(len(self))]).float()\n        self.max_seq_len = min(int(all_len.mean() + all_len.std() * 10), int(all_len.max()))\n\n    def pad_tokens(self, item: int):\n        tokens = self.captions_tokens[item]\n        padding = self.max_seq_len - tokens.shape[0]\n        if padding > 0:\n            tokens = torch.cat((tokens, torch.zeros(padding, dtype=torch.int64) - 1))\n            self.captions_tokens[item] = tokens\n        elif padding < 0:\n            tokens = tokens[:self.max_seq_len]\n            self.captions_tokens[item] = tokens\n        mask = tokens.ge(0)  # mask is zero where we out of sequence\n        tokens[~mask] = 0\n        mask = mask.float()\n        mask = torch.cat((torch.ones(self.prefix_length), mask), dim=0)  # adding prefix mask\n        return tokens, mask\n    \n    def __len__(self) -> int:\n        return len(self.captions_tokens)\n\n    def __getitem__(self, item):\n        tokens, mask = self.pad_tokens(item)\n        prefix = self.prefixes[item]\n        if self.normalize_prefix:\n            prefix = prefix.float()\n            prefix = prefix / prefix.norm(2, -1)\n        return tokens, mask, prefix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.get_device_name(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom transformers.optimization import Adafactor, AdafactorSchedule\n\nimport os\nimport pickle\nimport sys\nimport argparse\n\nfrom typing import Tuple, Optional, Union\nfrom torch.cuda.amp import autocast","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(\n    train_dataset: ClipCocoDataset,\n    valid_dataset: ClipCocoDataset,\n    model: ClipCaptionModel,\n    args,\n    warmup_steps: int = 2000,\n    output_dir: str = \".\",\n    output_prefix: str = \"\"\n):\n    #\n    batch_size = args.bs\n    epochs = args.epochs\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    model = freeze(model)\n\n\n    model.train()\n\n    optimizer = Adafactor(\n        model.parameters(),\n        lr=args.lr,\n        relative_step=False, # for adafactor\n    )\n\n    train_dataloader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True,\n    )\n    \n    valid_dataloader = DataLoader(\n        valid_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        drop_last=False,\n    )\n    \n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=warmup_steps,\n        num_training_steps=epochs * len(train_dataloader)\n    )\n    \n    #scheduler = AdafactorSchedule(optimizer) работает не оч\n\n    mean_epoch_train_loss = []\n    mean_epoch_validation_loss = []\n    \n    \n    for epoch in range(epochs):\n        loss_train_epoch = []\n        loss_valid_epoch = []\n        print(f\">>> Training epoch {epoch+1}\")\n        sys.stdout.flush()\n        progress = tqdm(total=len(train_dataloader), desc=output_prefix)\n        step=0\n        for idx, (tokens, mask, prefix) in enumerate(train_dataloader):\n            model.zero_grad()\n            step += 1\n            tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.bfloat16)\n            \n            outputs = model(tokens, prefix, mask)\n            logits = outputs.logits[:, train_dataset.prefix_length - 1: -1]\n\n            loss = nnf.cross_entropy(\n                logits.reshape(-1, logits.shape[-1]),\n                tokens.flatten().to(torch.int64),\n                ignore_index=0\n            )\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            optimizer.zero_grad()\n            progress.set_postfix({\"loss_train\": loss.item()})\n            \n\n            loss_train_epoch.append(loss.item())\n\n            if step % 500:\n                wandb.log({\"loss_train\":  loss.item()})\n            \n            progress.update()\n            if (idx + 1) % 7000 == 0:\n                torch.save(\n                    model.state_dict(),\n                    os.path.join(output_dir, f\"{output_prefix}_latest_gpt2_medium.pt\"),\n                )\n        progress.close()\n        if epoch % args.save_every == 0:\n            torch.save(\n                model.state_dict(),\n                os.path.join(output_dir, f\"{output_prefix}-{(epoch+1):03d}_gpt2_medium.pt\"),\n            )\n        \n        print(f\">>> Validation epoch {epoch+1}\")\n\n        progress = tqdm(total=len(valid_dataloader), desc=output_prefix)\n        step_validation=0\n        for idx, (tokens, mask, prefix) in enumerate(valid_dataloader):\n            step_validation+=1\n            with torch.no_grad():\n\n                tokens, mask, prefix = tokens.to(device), mask.to(device), prefix.to(device, dtype=torch.bfloat16)\n            \n                outputs = model(tokens, prefix, mask)\n                logits = outputs.logits[:, valid_dataset.prefix_length - 1: -1]\n\n                loss = nnf.cross_entropy(\n                    logits.reshape(-1, logits.shape[-1]),\n                    tokens.flatten().to(torch.int64),\n                    ignore_index=0\n                )\n\n\n\n            progress.set_postfix({\"loss_val\": loss.item()})\n\n            loss_valid_epoch.append(loss.item())\n            if step % 500:\n                wandb.log({\"loss_val\":  loss.item()})\n            \n            progress.update()\n\n        mean_epoch_train_loss.append(np.mean(loss_train_epoch))\n        mean_epoch_validation_loss.append(np.mean(loss_valid_epoch))\n        \n        wandb.log({\"mean_epoch_validation_loss\": mean_epoch_validation_loss[-1]})\n        wandb.log({\"mean_epoch_train_loss\": mean_epoch_train_loss[-1]})\n        \n        progress.close()\n        \n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Args():\n    def __init__(self):\n        self.backbone = gpt_model_name\n        self.train_data = \"Features_train_coco_ru_vitb16_82783.pkl\"\n        self.valid_data = \"Features_val_coco_ru_vitb16.pkl\"\n        self.out_dir = 'checkpoints'\n        self.prefix = 'first_start'\n        self.epochs = 2\n        self.save_every = 1\n        self.prefix_length = 30\n        self.bs = 2\n        self.only_prefix = False\n        self.lr = 2e-5\nargs = Args()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ClipCocoDataset(args.train_data, args.prefix_length, train=True)\nvalid_dataset = ClipCocoDataset(args.valid_data, args.prefix_length, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.config = {\n  \"learning_rate\": args.lr,\n  \"epochs\": args.epochs,\n  \"batch_size\": args.bs\n}\n\n\n\nmodel = ClipCaptionModel(args.prefix_length)\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train both prefix and LLAMA\")\nsys.stdout.flush()\nmodel = train(\n    train_dataset,\n    valid_dataset,\n    model,\n    args,\n    output_dir=args.out_dir,\n    output_prefix=args.prefix\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}